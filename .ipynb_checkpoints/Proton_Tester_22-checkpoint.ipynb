{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HZEOVDnjOA88"
   },
   "source": [
    "**Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gFYPubd9OE6N",
    "outputId": "e35457f8-c360-4fe7-f21d-c7e4dfd603aa"
   },
   "outputs": [],
   "source": [
    "# !pip3 install pandas --upgrade\n",
    "# !pip3 install swifter\n",
    "# !pip3 install xgboost\n",
    "# !pip3 install tqdm\n",
    "# !pip3 install category_encoders\n",
    "# !pip3 install joblib\n",
    "# !pip3 install scikit-plot \n",
    "# !pip3 install catboost\n",
    "# !pip3 install RegscorePy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SiXfeey8H7Zm"
   },
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vN9H7lBDH8fh",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/thegeorgejoseph/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "################################ ALL IMPORTS ################################\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FOR INIT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "import math\n",
    "\n",
    "# FOR Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For Date Engineering\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "import itertools\n",
    "import holidays\n",
    "\n",
    "#For Text Engineering\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "from textblob import TextBlob\n",
    "\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from gensim import corpora, models\n",
    "\n",
    "# For numeric Engineering\n",
    "import time\n",
    "\n",
    "# For Target Encoding\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# For feature Selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, f_regression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "# POST PROCESS AND MACHINE LEARNING\n",
    "from sklearn.preprocessing import PowerTransformer, LabelEncoder, MinMaxScaler, LabelBinarizer\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, mean_absolute_error,r2_score\n",
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import scikitplot as skplt\n",
    "import joblib\n",
    "\n",
    "# For debugging\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pfANlE6DUjuJ"
   },
   "source": [
    "**INPUT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ADDbm_Vlwxr9"
   },
   "outputs": [],
   "source": [
    "def importFile(path,nrows=None):\n",
    "\n",
    "    print('#### RUNNING WAIT ####')\n",
    "    \n",
    "    # IF THE EXTENSION IS CSV\n",
    "    def importCsv(path):\n",
    "        \n",
    "        print('We have a csv file')\n",
    "        try:\n",
    "            df = pd.read_csv(path,low_memory=False,nrows=nrows)\n",
    "            if df.shape[1] == 1:\n",
    "                df = pd.read_csv(path,low_memory=False,sep=';',nrows=nrows)                \n",
    "            print('This file has {} columns and {} rows'.format(df.shape[1],df.shape[0]))\n",
    "            return df       \n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print('File not found, Check the name, path, spelling mistakes')\n",
    "            error = True\n",
    "            return None    \n",
    "            \n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                enc = 'unicode_escape'\n",
    "                df = pd.read_csv(path,encoding=enc,low_memory=False,nrows=nrows)\n",
    "                print('This file has {} columns and {} rows'.format(df.shape[1],df.shape[0]))\n",
    "                return df\n",
    "                \n",
    "            except UnicodeDecodeError:\n",
    "                try:\n",
    "                    enc = 'ISO-8859-1'\n",
    "                    df = pd.read_csv(path,encoding=enc,low_memory=False,nrows=nrows)\n",
    "                    print('This file has {} columns and {} rows'.format(df.shape[1],df.shape[0]))\n",
    "                    return df\n",
    "                except:\n",
    "                    pass\n",
    "          \n",
    "        except:\n",
    "            try:\n",
    "                df= pd.read_csv(path,nrows=nrows)\n",
    "                separators= [\"~\",\"!\",\"@\",\"#\",\"$\",\"%\",\"^\",\"&\",\"*\",\":\",\"|\",\"/\",\";\"]     # all possible separators\n",
    "                if len(df.columns)<=3 :                                               # if separator was \",\" we would have more than 1 columns \n",
    "                    cols = df.columns[0]\n",
    "                    possibleSep = []   \n",
    "                    for i in separators:                                    # checking all the separators present in column names\n",
    "                        if i in cols:\n",
    "                            possibleSep.append(i)\n",
    "                        \n",
    "                    for j in possibleSep:                                   # iterate through possible seprators till we get the correct one\n",
    "                        df_sep = pd.read_csv(path,sep=j,nrows=nrows)\n",
    "                        if len(df_sep.columns)>3:\n",
    "                            print('This file has {} columns and {} rows'.format(df_sep.shape[1],df_sep.shape[0]))\n",
    "                            return df_sep\n",
    "            except:\n",
    "                try:\n",
    "                    if len(pd.read_csv(path,sep=None).columns,nrows=nrows)>3  :                   # for tab ie \"\\\" tsv files\n",
    "                        df = pd.read_csv(path,sep=None,nrows=nrows)\n",
    "                        print('This file has {} columns and {} rows'.format(df.shape[1],df.shape[0]))\n",
    "                        return df\n",
    "                except:        \n",
    "                    pass\n",
    "\n",
    "    # IF THE EXTENSION IS JSON\n",
    "    def importJSON(path):\n",
    "        try:\n",
    "            print('We have a JSON file')\n",
    "            df = pd.read_json(path)\n",
    "            print('This file has {} columns and {} rows'.format(df.shape[1],df.shape[0]))\n",
    "            return df    \n",
    "        except Exception:\n",
    "            try:\n",
    "                df = pd.read_json(path,lines=True)\n",
    "                print('This file has {} columns and {} rows'.format(df.shape[1],df.shape[0]))\n",
    "                return df\n",
    "        \n",
    "            except ValueError:\n",
    "                print('File not found, Check the name, path, spelling mistakes')\n",
    "                error = True\n",
    "                return None\n",
    "\n",
    "    def Excel_handler(dx):\n",
    "        # to handel cases when some blank rows or other information above the data table gets assumed to be column name \n",
    "        if (len([col for col in dx.columns if 'Unnamed' in col]) > 0.5*dx.shape[1]  ):#Checking for unnamed columns \n",
    "            colNew = dx.loc[0].values.tolist()           # Getting the values in the first row of the dataframe into a list\n",
    "            dx.columns = colNew                          #Making values stored in colNew as the new column names\n",
    "            dx = dx.drop(labels=[0])                     #dropping the row whose values we made as the column names\n",
    "            dx.reset_index(drop=True, inplace=True)      #resetting index to the normal pattern 0,1,2,3...\n",
    "        else:\n",
    "            return dx\n",
    "            \n",
    "        new_column_names=dx.columns.values.tolist() # Following three lines of code are for counting the number of null values in our new set of column names\n",
    "        new_column_names=pd.DataFrame(new_column_names)\n",
    "        null_value_sum=new_column_names.isnull().sum()[0]\n",
    "        if null_value_sum<0.5*dx.shape[1]: # if count of null values are less than a certain ratio of total no of columns\n",
    "            return dx\n",
    "        while(null_value_sum>=0.5*dx.shape[1]): \n",
    "            colNew = dx.loc[0].values.tolist()\n",
    "            dx.columns = colNew\n",
    "            dx = dx.drop(labels=[0])\n",
    "            dx.reset_index(drop=True, inplace=True)\n",
    "            new_column_names=dx.columns.values.tolist() \n",
    "            new_column_names=pd.DataFrame(new_column_names)\n",
    "            null_value_sum=new_column_names.isnull().sum()[0]\n",
    "        return dx \n",
    "\n",
    "    # IF THE EXTENSION IS XL\n",
    "    def importExcel(path):\n",
    "        try:\n",
    "            print('We have an Excel file')\n",
    "            df = pd.read_excel(path, sheet_name=None,nrows=nrows)\n",
    "            if len(df.keys())==1 :                               # checking if number of sheets is 1\n",
    "                df = Excel_handler(df[list(df.keys())[0]])\n",
    "                print('This file has {} columns and {} rows'.format(df.shape[1],df.shape[0]))\n",
    "                return df\n",
    "            else:                                                 # when more than 1 sheets, asking the user for data sheet name/number\n",
    "                print(\"Following are the sheets in the Excel file:\")\n",
    "                for c in range(len(df.keys())):\n",
    "                    print(str(c)+\".\",list(df.keys())[c])\n",
    "                sheet = input(\"Type the sheet name:  \")\n",
    "                keys = [x.lower() for x in list(df.keys())]\n",
    "                try:\n",
    "                    index = keys.index(sheet.lower())\n",
    "                    df = Excel_handler(df[list(df.keys())[index]])\n",
    "                    print('This sheet {} has {} columns and {} rows'.format(sheet,df.shape[1],df.shape[0]))\n",
    "                    return df\n",
    "                except:\n",
    "                    print('Sheet not found, Check the name, path, spelling mistakes')\n",
    "                    error = True\n",
    "                    return None\n",
    "        except FileNotFoundError:\n",
    "            print('File not found, Check the name, path, spelling mistakes')\n",
    "            error = True\n",
    "            return None\n",
    "\n",
    "\n",
    "    def importTable(path):\n",
    "        try:\n",
    "            print('We have General Table File')\n",
    "            df = pd.read_table(path,nrows=nrows)\n",
    "            if df.shape[1] == 1:\n",
    "                df = pd.read_table(path,sep=',',nrows=nrows)\n",
    "            print('This file has {} columns and {} rows'.format(df.shape[1],df.shape[0]))\n",
    "            return df\n",
    "        except FileNotFoundError:\n",
    "            print('File not found, Check the name, path, spelling mistakes')\n",
    "            error = True\n",
    "            return None\n",
    "            \n",
    "            \n",
    "    try:\n",
    "        ext = path.split('.')[1].lower()    \n",
    "        if ext == 'csv' or ext == 'tsv':\n",
    "            df = importCsv(path)\n",
    "            return df\n",
    "        elif ext == 'json':\n",
    "            df = importJSON(path)\n",
    "            return df\n",
    "        elif 'xl' in ext:\n",
    "            df = importExcel(path)\n",
    "            return df\n",
    "        elif ext == 'data':\n",
    "            df = importTable(path)\n",
    "            return df\n",
    "        else:\n",
    "            print('File format not supported\\n')\n",
    "    except:\n",
    "        print('Extension NOT FOUND!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gnh4oF0tIP76"
   },
   "source": [
    "**GETTING TARGET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kggCvUkOINbK"
   },
   "outputs": [],
   "source": [
    "def getTarget(columns):\n",
    "  \n",
    "    print('\\nEnter \\'quit\\' to quit')\n",
    "    target = input('What would you like to predict? : ')\n",
    "    if target == 'quit':\n",
    "        return None                    \n",
    "    elif target in columns:\n",
    "        print('Target Spotted!')\n",
    "        return target\n",
    "    else:\n",
    "        print('Target {} Not found in the data'.format(target))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lLv98W6k1a3t"
   },
   "source": [
    "**KEY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G1oGf_Cwvony"
   },
   "outputs": [],
   "source": [
    "def getKey(columns):\n",
    "    print('\\nEnter \\'quit\\' to quit')\n",
    "    key = input('Enter the Key/Identification Column : ')\n",
    "    if key == 'quit':\n",
    "        return None,False              \n",
    "    elif key in columns.values:\n",
    "        print('Key Spotted!')\n",
    "        return key\n",
    "    else:\n",
    "        print('Key {} Not found in the data'.format(key))\n",
    "        print('Preview can\\'t be shown!!')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Key if user didn't specify key from first column alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findKey(column):\n",
    "    if 'id' in column.lower():\n",
    "        dec = input(\"Is the column \\'{}\\' an identification column? If yes, enter y : \".format(column))\n",
    "        if dec == 'y':\n",
    "            print('Identification column obtained')\n",
    "            return column\n",
    "        else:\n",
    "            print('Identification column not obtained/found')\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M4qedFAVgVtA"
   },
   "source": [
    "**USER SPECIFIED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NK33CTihgRtT"
   },
   "outputs": [],
   "source": [
    "def removeUserSpecifiedIDs(df,successiveTarget=False):\n",
    "    removed_cols = set()\n",
    "    not_found_cols = set()\n",
    "    if not successiveTarget:\n",
    "        print('Would you like to remove any other ID,zip Code,Phone Numbers,UNIQUE lists, ')\n",
    "        print('Or columns that have only one unique entry? If yes, enter the column names below ')\n",
    "    else:\n",
    "        print('Do you think you have Successive Targets based on the current target? If yes, enter the column names below ')\n",
    "    print('in this format separated by commas: col1,col2,col3')\n",
    "    cols = input()\n",
    "    if not cols:\n",
    "        print('No Columns removed')\n",
    "        return df\n",
    "    else:\n",
    "        try:\n",
    "            columns = cols.split(',')\n",
    "            for column in columns:\n",
    "                if column in df.columns:\n",
    "                    df.drop(column,axis=1,inplace=True)\n",
    "                    removed_cols.add(column)\n",
    "                else:\n",
    "                    not_found_cols.add(column)\n",
    "            if removed_cols:\n",
    "                print('\\n{} columns are removed as entered by the user'.format(len(removed_cols)))\n",
    "            if not_found_cols:\n",
    "                print('\\n{}'.format(not_found_cols))\n",
    "                print('These columns were not found, hence not removed')\n",
    "            return df\n",
    "        except:\n",
    "            print('Invalid Entry of columns! No Columns removed')\n",
    "            return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c78YeYBJv0NH"
   },
   "source": [
    "**Identify Date Columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5MLSz3sv5lB"
   },
   "outputs": [],
   "source": [
    "######################## ----------------- DATE IDENTIFICATION --------------------- ######################\n",
    "\n",
    "# Global List of all months\n",
    "months = ['jan','feb','mar','apr','may','jun','jul','aug','sep','oct','nov','dec']\n",
    "\n",
    "def getDateColumns(df,withPossibilies=0):\n",
    "    '''\n",
    "    This method Identifies all columns with 'DATE' data by maximizing out the possibilities\n",
    "    '''\n",
    "    # First get all non-numerical Columns\n",
    "    non_numeric_cols = df.select_dtypes('object')\n",
    "    # This dictionary stores possibilities of a column containing 'DATES' based on the name of the column\n",
    "    Possibility = {}\n",
    "    for column in non_numeric_cols:\n",
    "        if 'date' in column.lower():                  \n",
    "            Possibility[column] = int(len(df)*0.1)\n",
    "        else:\n",
    "            Possibility[column] = 0\n",
    "        for entry in df[column]:                                                    # ITERATE THROUGH EVERY ENTRY AND TRY SPLITTING THE VALUE AND INCREMENT/DECREMENT POSSIBILITY \n",
    "            try:                                                                      # USING EXCEPTION HANDLING\n",
    "                if len(entry.split('/')) == 3 or len(entry.split('-')) == 3 or len(entry.split(':')) == 3:\n",
    "                    Possibility[column] += 1\n",
    "                    for month in months:\n",
    "                        if month in entry.lower():\n",
    "                            Possibility[column] += 1 \n",
    "                else:\n",
    "                    Possibility[column] -= 1\n",
    "            except:\n",
    "                Possibility[column] -= 1        \n",
    "      # This contains the final DATE Columns\n",
    "    DATE_COLUMNS = []\n",
    "    for key,value in Possibility.items():             \n",
    "        if value > 0.8 * len(df):                                                  # IF THE POSSIBILITY OF THE COLUMN IN GREATER THAN 1, THEN IT IS DEFINITELY A 'DATE COLUMN'\n",
    "            DATE_COLUMNS.append(key)    \n",
    "    if not withPossibilies:\n",
    "        return DATE_COLUMNS\n",
    "    else:\n",
    "        return DATE_COLUMNS,Possibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y7kNSWPQwBkF"
   },
   "source": [
    "**Date Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBRZTl9UwDpR"
   },
   "outputs": [],
   "source": [
    "def date_engineering(df):\n",
    "    start = time.time()\n",
    "    date_cols = df.columns\n",
    "    print('\\n\\t Entering Date Engineering')\n",
    "    df = df.swifter.apply(pd.to_datetime)\n",
    "    df.fillna(pd.datetime.now(),inplace=True)\n",
    "    \n",
    "    # creating separate month and year columns\n",
    "    for i in date_cols:\n",
    "        df[str(i)+\"_month\"] = df[str(i)].dt.month.astype(int)\n",
    "        df[str(i)+\"_year\"] = df[str(i)].dt.year.astype(int)\n",
    "    \n",
    "    # create difference columns\n",
    "    if (len(date_cols)>1) :\n",
    "        for i in itertools.combinations(date_cols,2):\n",
    "            df[str(i[0])+\" - \"+str(i[1])]=(df[i[0]]-df[i[1]]).dt.days.astype(int)\n",
    "    \n",
    "    # create most recent\n",
    "    for i in date_cols:\n",
    "        df[str(i)+\"-most_recent\"] = (max(df[str(i)])-df[str(i)]).dt.days.astype(int)\n",
    "    \n",
    "    print('\\n\\t #### RUNNING WAIT ####')\n",
    "    \n",
    "    # See Near Holiday or not \n",
    "    def nearHol(currentDate, us_hols, currentYear):\n",
    "        new_list = []\n",
    "        append = new_list.append\n",
    "        for date, occasion in us_hols:\n",
    "            if(date.year == currentYear):\n",
    "                append(date)\n",
    "        flag = 1\n",
    "        for i in new_list:\n",
    "            a = (currentDate.date()-i).days\n",
    "\n",
    "            if abs(a)<=5:flag =1;break\n",
    "            else:flag = 0\n",
    "                \n",
    "        return 0 if flag == 0 else 1\n",
    "        \n",
    "    for col in date_cols:\n",
    "#         print('LOOP')\n",
    "        #creating a unique list of all years corresponding to a column to minimise mapping\n",
    "        us_hols = holidays.US(years=df[str(col)+'_year'].unique(), expand= False) \n",
    "        #creating a new columns to check if a date falls near a holiday\n",
    "        df[str(col)+'_Holiday'] = df.apply(lambda x: nearHol(x[col],us_hols.items(),x[str(col)+'_year']),axis=1) \n",
    "    \n",
    "    end = time.time()\n",
    "    print('\\nDate Engineering Time Taken : {}'.format(end-start))\n",
    "    print('\\n\\t #### DONE ####')\n",
    "    return df.drop(date_cols,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findReviewColumns(df): #input main dataframe \n",
    "  \n",
    "  rf = df.sample(n=150, random_state=1).dropna(axis=0) if len(df)>150 else df.dropna(axis=0)#use frac=0.25 to get 25% of the data\n",
    "  \n",
    "  #df.dropna(axis=0,inplace=True) #dropping all rows with null values\n",
    "\n",
    "  \n",
    "\n",
    "  #categorical_variables = []\n",
    "  col_list =[]\n",
    "  for col in rf.columns:\n",
    "    if df[col].nunique() <100:\n",
    "      col_list.append(col)           #define threshold for removing unique values #replace with variable threshold\n",
    "      rf.drop(col, axis=1,inplace=True) #here df contains object columns, no null rows, no string-categorical,\n",
    "\n",
    "  \n",
    "  rf.reset_index(drop=True,inplace=True)\n",
    "  for col in rf.columns:\n",
    "        count1,count2,count3,count4 = 0,0,0,0\n",
    "        for i in range(len(rf)):\n",
    "            val = len(str(rf.at[i,col]).split())\n",
    "            if val == 1:\n",
    "                count1 = count1+1\n",
    "            elif val == 2:\n",
    "                count2 = count2+1\n",
    "            elif val == 3:\n",
    "                count3 = count3+1\n",
    "            elif val == 4:\n",
    "                count4 = count4+1\n",
    "        print(col,\"count of words is\",count1,\"-\",count2,\"-\",count3,\"-\",count4,\"-\")\n",
    "        \n",
    "        if count1+count2+count3+count4 >=0.75*len(rf):\n",
    "            col_list.append(col)\n",
    "            print(\"dropping column\",col)\n",
    "            rf.drop(col, axis=1,inplace=True)\n",
    "        \n",
    "  \n",
    "         \n",
    "\n",
    " \n",
    "  start = time.time()\n",
    "  print(rf.shape)\n",
    "  nlp = spacy.load('en_core_web_sm', disable=['tagger','parser','textcat'])\n",
    "  sf = pd.DataFrame()\n",
    "  for col in rf.columns:\n",
    "    sf[col] = rf[col].apply(nlp)\n",
    "\n",
    "\n",
    "  end = time.time()\n",
    "  print(\"Time taken to tokenize the DataFrame\",end - start)\n",
    "\n",
    "  #print(\"Tokenised Sampled DataFrame\",sf)\n",
    "  #print(\"Sampled DataFrame\",rf)\n",
    "  #print(\"Actual Dataframe\",df)\n",
    "\n",
    "  start = time.time()\n",
    "  #testf = sf.sample(frac=0.10,random_state=44)\n",
    "  \n",
    "  #code to eliminate columns of name, city, address\n",
    "  for col in sf.columns:\n",
    "    entity_list =[]\n",
    "    tokens = nlp(''.join(str(sf[col].tolist()))) #converting one column into tokens\n",
    "    #print(\"the tokens of each column are:\", tokens)\n",
    "    token_len = sum(1 for x in tokens.ents)\n",
    "    print(\"Length of token entities\",token_len)                                    #create two lists that hold the value of actual token entities and matched token entities respectively\n",
    "    if token_len>0:\n",
    "      for ent in tokens.ents:\n",
    "        if (ent.label_ == 'GPE') or (ent.label_ =='PERSON'):  #matching is done on the basis of whether the entity label is \n",
    "          entity_list.append(ent.text)          #countries, cities, state, person (includes fictional), nationalities, religious groups, buildings, airports, highways, bridges, companies, agencies, institutes, DATE etc.\n",
    "\n",
    "      entity_counter = Counter(entity_list).elements()  #counts the match\n",
    "      counter_length = sum(1 for x in entity_counter) \n",
    "      print(\"Length of matched entities\",counter_length) #if there is at least a 50% match, we drop that column TLDR works better on large corpus\n",
    "      if (counter_length >= 0.60*token_len):\n",
    "        col_list.append(col)\n",
    "    else:\n",
    "      print(\"Length of token entities 0\")\n",
    "      print(\"Length of matched entities 0\")\n",
    "    counter_length = 0\n",
    "    token_len = 0\n",
    "  \n",
    "\n",
    "  print(\"Columns that are going to be removed are \", col_list)   #list of columns that need to be removed\n",
    "  ##########IMPORTANT LINE NEXT###############\n",
    "  rf = df.copy() #unhide this to immediately work with the entire dataset and not just sampled dataset and vice-versa to work with sampled\n",
    "  ##########DO NOT IGNORE ABOVE LINE##########\n",
    "  for val in col_list:\n",
    "    rf.drop(val, axis=1, inplace=True) \n",
    "  end = time.time()\n",
    "  print(\"Time taken for completion of excess column removal:\", end-start)\n",
    "\n",
    "  if (len(rf.columns) ==0):\n",
    "    print(\"No Remarks or Comments Found \")\n",
    "    flag = 0\n",
    "    return None, None\n",
    "  else:\n",
    "    flag = 1\n",
    "\n",
    "  if (flag == 1):\n",
    "    main_list = [] #holds all the review columns\n",
    "    append = main_list.append\n",
    "    for col in rf.columns:\n",
    "      append(col)\n",
    "    \n",
    "    return main_list, col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(rf):\n",
    "  bf = pd.DataFrame()\n",
    "  def getSubjectivity(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.subjectivity #returns subjectivity of the text\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "  def getPolarity(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.polarity  #returns polarity of the sentiment\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "  for col in rf.columns:      #creating a new DataFrame with new columns\n",
    "    col_pname = \"{}-{}\".format(col,\"Polarity\")\n",
    "    col_sname = \"{}-{}\".format(col,\"Subjectivity\")\n",
    "    bf[col_pname] = rf[col].apply(getPolarity)\n",
    "    bf[col_sname] = rf[col].apply(getSubjectivity)\n",
    "   \n",
    "  \n",
    "  \n",
    "  return bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v')) #performs lemmatization\n",
    "    \n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:  #removes stopwords and tokens with len>3\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topicExtraction(df,validation=False,lda_model_tfidf=None):\n",
    "\n",
    "  data_text = df.copy()\n",
    "  data_text['index'] = data_text.index\n",
    "  documents = data_text\n",
    "\n",
    "  headline = list(documents.columns)[0] #review column\n",
    "\n",
    "  processed_docs = documents[headline].map(preprocess) #preprocessing review column\n",
    "\n",
    "  #print(\"Processed Docs are as follows\",processed_docs[:10])\n",
    "\n",
    "  dictionary = gensim.corpora.Dictionary(processed_docs) #converting into gensim dict\n",
    "  dictionary.filter_extremes(no_below=10,no_above=0.25, keep_n=1000)   #taking most frequent tokens\n",
    "\n",
    "  bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs] #document to bag of words\n",
    " \n",
    "  if validation==False:\n",
    "    #print(\"BOW Corpus\", bow_corpus[:10])\n",
    "    tfidf = models.TfidfModel(bow_corpus)\n",
    "    corpus_tfidf = tfidf[bow_corpus] #generating the TF-IDF of the corpus \n",
    "\n",
    "    start = time.time()\n",
    "    lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=1, workers=10) #multiprocessing Latent Dirilichtion Allocation Model\n",
    "    end = time.time()\n",
    "    print(end-start)\n",
    "    for idx, topic in lda_model_tfidf.print_topics(-1): \n",
    "        print('Topic: {} Word: {}'.format(idx, topic)) #printing topics in the corpus\n",
    "\n",
    "\n",
    "  ser = []\n",
    "  append = ser.append\n",
    "  print(\"Bag of Words Corpus length\",len(bow_corpus))\n",
    "  start = time.time()\n",
    "  for i in range(len(bow_corpus)):\n",
    "    for idx, topic in sorted(lda_model_tfidf[bow_corpus[i]], key= lambda tup: -1*tup[1]):\n",
    "      append(idx)\n",
    "      break\n",
    "  end = time.time()\n",
    "  asf = pd.DataFrame(ser)\n",
    "  print(\"Time for append\", end-start)  \n",
    "  \n",
    "\n",
    "  return asf, lda_model_tfidf\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xig8viUvsaoA"
   },
   "source": [
    "**Numeric Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pL23AHs36Dzh"
   },
   "outputs": [],
   "source": [
    "# Numeric Engineering 1(To be tested)\n",
    "#For converting allnumeric data in columns like currency remperature, numbers in numeric form etc.. into numeric form\n",
    "def numeric_engineering(df):\n",
    "    start = time.time()  \n",
    "    \n",
    "    def returnMoney(col):\n",
    "        # Remove Commas from currencies\n",
    "        try:\n",
    "            return pd.to_numeric(col.str.replace(',',''))\n",
    "        except:\n",
    "            return col\n",
    "        \n",
    "    obj_columns= list(df.dtypes[df.dtypes == np.object].index)\n",
    "    # print(f'object type columns are {obj_columns}') \n",
    "    print(f'\\t\\t stripping spaces, symbols, and lower casing all entries')\n",
    "    df[obj_columns]=df[obj_columns].swifter.apply(lambda x: x.astype(str).str.strip(' %$€£¥').str.lower())\n",
    "    print('done ...')\n",
    "    print(f'\\t\\t Replacing empty and invalid strings')\n",
    "    df[obj_columns]=df[obj_columns].replace(['-','n/a','na','nan','nil',np.inf,-np.inf],[np.nan,np.nan,np.nan,np.nan,np.nan,np.nan,np.nan])\n",
    "    print('done ...')\n",
    "    print(f'\\t\\t Replacing commas if present in Currencies')\n",
    "    df[obj_columns]=df[obj_columns].swifter.apply(lambda x:returnMoney(x))\n",
    "    print('done ...')\n",
    "    obj_columns= list(df.dtypes[df.dtypes == np.object].index)\n",
    "    df1 = df[obj_columns].copy()\n",
    "    print(f'\\t\\t Finding Numeric Columns')\n",
    "    df1 = df1.swifter.apply(lambda x : pd.to_numeric(x,errors='coerce'))\n",
    "    df1.dropna(axis=1,thresh = 0.65*len(df),inplace=True)\n",
    "    new_num_cols = df1.columns\n",
    "    df[new_num_cols] = df[new_num_cols].swifter.apply(lambda x : pd.to_numeric(x,errors='coerce'))\n",
    "    print('done ...')\n",
    "\n",
    "    for i in df.columns :\n",
    "        print(f'\\t\\t   {i} is of type {df[i].dtypes}')\n",
    "\n",
    "    # # End of Testing codes\n",
    "    end = time.time();print('Numeric Engineering time taken:',end - start);print('\\n')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ECAW9q3NW-qY"
   },
   "source": [
    "## Segregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ExlScim9W-qY"
   },
   "outputs": [],
   "source": [
    "def Segregation(df):\n",
    "    print('\\n#### Entering Segregation ####')\n",
    "    start = time.time()\n",
    "    num = df._get_numeric_data().columns\n",
    "    obj = list(set(df.columns)-set(num))\n",
    "    \n",
    "    nu = df[num].nunique()>5\n",
    "    numeric = df[nu[nu == True].index]   \n",
    "    cat_num = df[list(set(num) - set(numeric.columns))]\n",
    "    numeric.fillna(numeric.mean(),inplace=True)\n",
    "    cat_num.fillna('missing',inplace=True)\n",
    "    \n",
    "    unique = []\n",
    "    discrete = []\n",
    "    \n",
    "    def func(column):\n",
    "        l=column.value_counts(normalize=True)\n",
    "        minor=l[l<=0.005].index\n",
    "        if len(minor) > 0:\n",
    "            print('\\n{} contains {} categories that is/are less than 0.5 percent'.format(column.name, len(minor)))  \n",
    "            if (column.nunique() - len(minor)) in range(1,61):\n",
    "                discrete.append(column.name)\n",
    "                column.replace(minor,'others',inplace=True)\n",
    "            else:\n",
    "                unique.append(column.name)\n",
    "        else:\n",
    "            discrete.append(column.name)\n",
    "    \n",
    "    df[obj].apply(func)\n",
    "    \n",
    "    if None in discrete:\n",
    "        discrete = []\n",
    "        df[discrete].fillna('missing',inplace=True)\n",
    "    else:\n",
    "        df[discrete].fillna('missing',inplace=True)\n",
    "    \n",
    "    print('\\n Grouped Minor Levels and imputed')\n",
    "    print('\\n The useless columns are {}'.format(unique))\n",
    "    end = time.time()\n",
    "    print('Segregation time taken : {}'.format(end-start))\n",
    "    return numeric,pd.concat([cat_num,df[discrete]],axis=1),unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PksfnOishiLB"
   },
   "source": [
    "**Dataset Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kWfrJleChiLC"
   },
   "outputs": [],
   "source": [
    "def DatasetSelection(X,Y):\n",
    "  X1=X.copy()\n",
    "  X2=X.copy()\n",
    "  index=list(X.index)\n",
    "  #Row then column\n",
    "  X1.dropna(axis=0,thresh=0.5*len(X1.columns),inplace=True)#dropping the rows with many null values\n",
    "  index1=list(X1.index)#storing the indices of the dataframe after the operation in index1\n",
    "  X1.dropna(axis=1,thresh=0.5*len(X1),inplace=True)#dropping columns\n",
    "  if len(X1.columns)==0:#in case if all columns get dropped then in result there should be no rows in the dataframe\n",
    "    index1=[] #in this case list of row indices equal to null list\n",
    "  Rowsdrop1=(list(set(index)-set(index1)))#storing the indices of the rows getting dropped above\n",
    "  #column then row\n",
    "  X2.dropna(axis=1,thresh=0.5*len(X2),inplace=True)#dropping the columns with many null values\n",
    "  X2.dropna(axis=0,thresh=0.5*len(X2.columns),inplace=True)#dropping rows\n",
    "  index2=list(X2.index)#storing its indices in a list\n",
    "  if len(X2.columns)==0:\n",
    "    index2=[]\n",
    "  Rowsdrop2=(list(set(index)-set(index2)))#storing the indices of the rows getting dropped above\n",
    "  if len(Rowsdrop1)<len(Rowsdrop2): #checking in which case is number of rows getting dropped is lesser\n",
    "    Y.drop(Rowsdrop1,inplace=True)\n",
    "    print(\"Columns are getting dropped first then columns\")\n",
    "    print(\"The columns getting dropped are {}\".format(list(set(X.columns)-set(X1.columns))))\n",
    "    print(\"Shape of the dataframe: {}\".format(X1.shape))\n",
    "    print(\"Shape of the target column {}\".format(Y.shape))\n",
    "    return X1,Y #returns resultant dataframe and target column\n",
    "  else:\n",
    "    Y.drop(Rowsdrop2,inplace=True)  \n",
    "    print(\"Rows are getting dropped first then rows\")\n",
    "    print(\"The columns getting dropped are {}\".format(list(set(X.columns)-set(X2.columns))))\n",
    "    print(\"Shape of the dataframe: {}\".format(X2.shape))\n",
    "    print(\"Shape of the target column {}\".format(Y.shape))\n",
    "    return X2,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FVhcAZWIqlTo"
   },
   "source": [
    "**TARGET ANALYSIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vNBupvO6XPT"
   },
   "outputs": [],
   "source": [
    "def targetAnalysis(df):\n",
    "    print('\\n### TARGET ANALYSIS ENTERED ###')\n",
    "    Type = str(df.dtypes)\n",
    "    # IF INT OR FLOAT IN TARGET, and IF NUMBER OF UNIQUE IS LESS, CLASSIFICATION, ELSE, REGRESSION\n",
    "    print('Target has {} unique values'.format(df.nunique()))\n",
    "    if ('int' in Type) or ('float' in Type):\n",
    "        if df.nunique() < 5:\n",
    "            return 'Classification'\n",
    "        else:\n",
    "            return 'Regression'\n",
    "        \n",
    "    else:\n",
    "        if df.nunique() < 5:\n",
    "            return 'Classification'\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e6D9FeY0JuAA"
   },
   "source": [
    "**Sample Equation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dSnuXIeLJXpv"
   },
   "outputs": [],
   "source": [
    "def SampleEquation(X,Y,class_or_Reg):\n",
    "    if class_or_Reg == 'Classification':# for classification\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        model=LogisticRegression(max_iter=400)\n",
    "        kb = SelectKBest( score_func=f_classif,k=8) #for selecting the 8 best features\n",
    "        if len(X.columns)>8:#to limit the size of equation. restricting to be less than 9 variables \n",
    "            kb.fit_transform(X,Y) \n",
    "            new_features = []\n",
    "            mask=kb.get_support() #This returns an array with true /false values with true for those columns which got selected\n",
    "            for bool, feature in zip(mask,X.columns):#to extract column names from mask\n",
    "                if bool:\n",
    "                    new_features.append(feature)\n",
    "            X=X[new_features]\n",
    "\n",
    "        model.fit(X,Y)\n",
    "        if Y.nunique()==2: #if there are only two classes\n",
    "            for i in range(len(model.coef_)): # for dispaying the equation curresponding to all classes\n",
    "                s=\"\"\n",
    "                for j in range(len(model.coef_[i])):\n",
    "                    s=s+str(model.coef_[i][j])+\"*\"+X.columns[j]+\" + \"\n",
    "                s=s+str(model.intercept_[i])\n",
    "\n",
    "                print(\"Power term = \"+s+\"\\n\")\n",
    "                print(\"Probability(Y=1) = exp(Power term)/(exp(Power term) + 1)\\n\")\n",
    "        else:#multiclass classification\n",
    "            for i in range(len(model.coef_)): # for dispaying the equation curresponding to all classes\n",
    "                s=\"\"\n",
    "                for j in range(len(model.coef_[i])):\n",
    "                    s=s+str((model.coef_[i][j]))+\"*\"+X.columns[j]+\" + \"\n",
    "                s=s+str(model.intercept_[i])\n",
    "\n",
    "                print(\"Prediction of class \"+ str(model.classes_[i])+\"\\n\\n\")\n",
    "                print(\"Power term= \" + s)\n",
    "                print(\"\\nPrediction(class={}) = exp(Power term)/(exp(Power term) + 1)\\n\".format(model.classes_[i]))\n",
    "    else:#regression problem\n",
    "        from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        model=LinearRegression()\n",
    "        if len(X.columns)>8:#Executing forward feature selection\n",
    "            sfs = SFS(model,\n",
    "               k_features=8,\n",
    "               forward=True,\n",
    "               floating=False,\n",
    "               scoring = 'r2',\n",
    "               cv = 0)\n",
    "            sfs.fit(X,Y)\n",
    "            X=X[list(sfs.k_feature_names_)] \n",
    "        model.fit(X,Y)\n",
    "        coeff=model.coef_\n",
    "        equation=\"\"\n",
    "        for i in range(len(coeff)):\n",
    "            equation= equation+str(coeff[i])+\"*\"+X.columns[i]+\" + \"\n",
    "        equation=equation+str(model.intercept_)\n",
    "\n",
    "        print('Linear Equation is : {}'.format(equation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Imm4g_zHW-qh"
   },
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-GsyDUyW-qi"
   },
   "outputs": [],
   "source": [
    "def FeatureSelection(X,y,class_or_Reg):\n",
    "    n_est = 10\n",
    "    if class_or_Reg == 'Classification': \n",
    "        selector = XGBClassifier(n_estimators =n_est, max_depth= 6, n_jobs=-1)\n",
    "        print('runnning classifier selector')\n",
    "    else : \n",
    "        selector = XGBRegressor(n_estimators =n_est, max_depth= 6, n_jobs=-1)\n",
    "        print('runnning regressor selector')\n",
    "    \n",
    "    for i in tqdm(range(10)):\n",
    "        selector.fit(X, y) \n",
    "    \n",
    "    # all columns container\n",
    "    cols = pd.DataFrame(X.columns)\n",
    "\n",
    "    # Getting importance scores of all the features\n",
    "    k = selector.feature_importances_\n",
    "    k = k.reshape(X.shape[1],1)\n",
    "    k = pd.DataFrame(k)\n",
    "\n",
    "    # threshold one(This thres is able to select only top best features which are very few)\n",
    "    thresh1 = k.mean(); l = k>thresh1\n",
    "    sheet1 = pd.concat([cols, k, l], axis =1)\n",
    "    sheet1.columns = ['col_name','scores1','t/f']\n",
    "    new_1 = sheet1.loc[(sheet1['t/f'] == False)] \n",
    "\n",
    "    # threshold two(The mean of the remaining features is used as a thres)\n",
    "    thresh2 = new_1['scores1'].mean(); l2 = k>thresh2\n",
    "    sheet2 = pd.concat([cols, k, l2], axis =1)\n",
    "    sheet2.columns = ['col_name','scores2','t/f']\n",
    "    new_2 = sheet2.loc[(sheet2['t/f'] == True)]\n",
    "\n",
    "    # Final Score Sheet\n",
    "    new_2 = new_2.sort_values('scores2', ascending=False)\n",
    "    print('\\nThe final score sheet of {} selected columns with importances:\\n' .format(new_2.shape[0]))\n",
    "    print(new_2)\n",
    "    \n",
    "    rejected_cols = set(X.columns) - set(new_2.col_name)\n",
    "    print('\\n{} columns are eliminated during Feature Selection which are:\\n{}' .format(len(rejected_cols), rejected_cols))\n",
    "    return list(rejected_cols),new_2.drop(['t/f'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x9neMmWFW-qj"
   },
   "source": [
    "## User Interact Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k6-UII9fW-qj"
   },
   "outputs": [],
   "source": [
    "def bivar_ploter(df1,targ,base_var,ax1):    \n",
    "      l=[]\n",
    "      for b in set(df1[targ]):l.append((df1[df1[targ]==b].groupby(base_var).count()[targ]).rename(b))\n",
    "      c=pd.concat(l,axis=1)\n",
    "      if(df1[targ].nunique()>5):\n",
    "          a=list(c.sum(axis=0).sort_values(ascending=False)[:4].index)\n",
    "          c=pd.concat([c[a],pd.Series(c[list(set(c.columns)-set(a))].sum(axis=1),name='Others')],axis=1)\n",
    "      if(df1[base_var].dtype==np.object or df1[base_var].nunique()/len(df1)>0.1):\n",
    "          if(df1[base_var].nunique()<10):a=c.plot(kind='bar',ax=ax1)\n",
    "          else:a=c.loc[list(c.sum(axis=1).sort_values().index)[-10:]].plot(kind='bar',ax=ax1)\n",
    "          ax1.set_title(base_var)\n",
    "      else:\n",
    "          a=c.plot(kind='line',alpha=0.5,ax=ax1)\n",
    "      ax1.set_ylabel('Frequency')\n",
    "      return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AwmZg9ugW-qk"
   },
   "outputs": [],
   "source": [
    "def userInteractVisualization(df1,targ):\n",
    "        B=list(df1.columns);B.remove(targ);l=[]\n",
    "        x=df1.apply(lambda x:np.sum(x.value_counts(normalize=True).iloc[:min(10,x.nunique())])<0.10)\n",
    "        if(df1[targ].nunique()>4 and df1[targ].dtype!=np.object):j=np.sum(df1.dtypes==np.object)-np.sum(x)\n",
    "        else:j=len(df1.columns)-np.sum(x & df1.dtypes==np.object)-1\n",
    "        nr=int((j/4)+0.99)\n",
    "        print('\\t Applying bivar_plotting to create Images ...') # For Testing\n",
    "        start = time.time() \n",
    "        fig, axes = plt.subplots(ncols=4,nrows=nr,figsize=(20,6*nr));axes=axes.ravel();i=0\n",
    "        if(df1[targ].nunique()>5 and df1[targ].dtype!=np.object):        \n",
    "            for c in (df1.dtypes.loc[(df1.dtypes==np.object).values].index):\n",
    "                #Plots for cat features done if top 10 unique_values account for >10% of data (else visulaisation is significant)\n",
    "                if(np.sum(df1[c].value_counts(normalize=True).iloc[:min(10,df1[c].nunique())])<0.10):continue\n",
    "                try:\n",
    "                    bivar_ploter(df1,c,targ,axes[i]);i=i+1\n",
    "                except:\n",
    "                    pass\n",
    "        else:    \n",
    "            for c in B:\n",
    "                #Plots for cat features done if top 10 unique_values account for >10% of data (else visulaisation is significant)\n",
    "                if(np.sum(df1[c].value_counts(normalize=True).iloc[:min(10,df1[c].nunique())])<0.10 and df1[c].dtype==np.object):continue\n",
    "                try:\n",
    "                    bivar_ploter(df1,targ,c,axes[i]);i=i+1\n",
    "                except:\n",
    "                    pass\n",
    "        for c in range(i,(4*nr)):axes[c].set_visible(False)\n",
    "        print('\\n Target analysis');fig.suptitle(targ);fig.tight_layout();fig.show()\n",
    "        print(f'\\t Done with Bivar plotting in time {time.time() - start} seconds ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0nuKKDYNW-qm"
   },
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UOeuF0zxW-qm"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "import random\n",
    "from pprint import pprint\n",
    "from itertools import combinations\n",
    "import ast # ast.literal_eval(str(best))\n",
    "from time import process_time \n",
    "import time\n",
    "from decimal import Decimal\n",
    "\n",
    "# Model\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "#Hyperopt\n",
    "import hyperopt\n",
    "from hyperopt import *\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "#sklearn library\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import compute_sample_weight\n",
    "\n",
    "import xgboost as xgb\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "class classification:\n",
    "    \n",
    "  #This funciton takes input of training and testing datasets and give out the best model's Name, model with best parameter(can be used directly to score data using 'predcit' function), accuracy on the test dataset and parameters (not usefful)\n",
    "  ###############################################################################################################################\n",
    "  def best_model_class(self,X_train ,X_test, y_train, y_test,priorList,q_s,MAX_EVALS=15,CV=5):\n",
    "      df=pd.DataFrame()\n",
    "      print(\"Q_S value passed is!!!!\",q_s)\n",
    "      class_weights = list(class_weight.compute_class_weight('balanced',\n",
    "                                             np.unique(y_train),\n",
    "                                             y_train))\n",
    "\n",
    "      class_w= pd.Series(class_weights,index=np.unique(y_train))\n",
    "      w_array = np.ones(y_train.shape[0], dtype = 'float')\n",
    "      for i,val in enumerate(y_train):          #create a weight array to enter the booster\n",
    "        w_array[i] = class_w[val]\n",
    "     \n",
    "      maxval = priorList.max()\n",
    "      print(maxval)\n",
    "      minval = priorList.min()\n",
    "      print(minval)\n",
    "      myval = math.ceil(maxval/minval)\n",
    "      print(myval)\n",
    "      \n",
    "      print(\"PRIOR LIST IS\",priorList)\n",
    "      flag = 1\n",
    "      check = 1\n",
    "      if len(priorList) == 2:\n",
    "        check =1  #binary classification problem\n",
    "        for val in priorList:\n",
    "          if val <= 0.25:\n",
    "            flag = 0\n",
    "            check =1  #binary classification problem\n",
    "      elif len(priorList) >2:\n",
    "        check =0 #multiclassification problem\n",
    "        for val in priorList:\n",
    "          if val <= 0.15:\n",
    "            flag = 0\n",
    "            \n",
    "      if q_s ==True:  #QUICK RESULTS\n",
    "        ind=0\n",
    "        best = {}\n",
    "        #XGBoost\n",
    "        #######################################################################\n",
    "        df.loc[ind,'Name']='XGBoost'\n",
    "        if check == 1:\n",
    "            df.loc[ind,'model']=xgb.XGBClassifier(n_estimators=100,eta= 0.1,max_depth=16,min_child_weight=2,gamma=5,subsample=0.1,scale_pos_weight=1,eval_metric='logloss')\n",
    "        elif check ==0:\n",
    "            df.loc[ind,'model']=xgb.XGBClassifier(n_estimators=100,eta= 0.1,max_depth=16,min_child_weight=2,gamma=5,subsample=0.1,objective=\"multi:softmax\",scale_pos_weight=1,eval_metric='mlogloss',num_class=len(priorList))\n",
    "            \n",
    "        df.loc[ind,'param']=str(best)\n",
    "        Start=time.time()\n",
    "        eval_set = [(X_test, y_test)]\n",
    "        if check ==1:\n",
    "            df.loc[ind,'model'].fit(X_train, y_train, eval_metric=\"logloss\", eval_set=eval_set,verbose=False)\n",
    "        elif check==0:\n",
    "            df.loc[ind,'model'].fit(X_train, y_train,sample_weight = w_array, eval_metric=\"mlogloss\", eval_set=eval_set,verbose=False)\n",
    "        \n",
    "        xgb_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, xgb_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, xgb_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, xgb_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, xgb_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, xgb_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, xgb_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, xgb_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, xgb_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, xgb_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, xgb_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)       \n",
    "        print(\"XGB val done\")\n",
    "        ind=ind+1\n",
    "        ########################################################################################################\n",
    "    \n",
    "        ##Catboost\n",
    "        ########################################################################################################\n",
    "        df.loc[ind,'Name']='CatBoost'\n",
    "        if check==1:\n",
    "            df.loc[ind,'model']=cb.CatBoostClassifier(depth=10,iterations=1000,learning_rate=0.1,rsm=1.0,auto_class_weights=\"Balanced\")\n",
    "        elif check==0:\n",
    "            df.loc[ind,'model']=cb.CatBoostClassifier(depth=10,iterations=1000,learning_rate=0.1,rsm=1.0,auto_class_weights=\"Balanced\",loss_function='MultiClass')\n",
    "        df.loc[ind,'param']=str(best)\n",
    "        Start=time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train,eval_set=eval_set,verbose=False)\n",
    "        catboost_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, catboost_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, catboost_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, catboost_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, catboost_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, catboost_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, catboost_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_testbin, catboost_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, catboost_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, catboost_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, catboost_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "        print(\"CAT val done\")\n",
    "        ind=ind+1\n",
    "        ########################################################################################################\n",
    "        \n",
    "          \n",
    "        ##LGBM\n",
    "        ########################################################################################################\n",
    "        df.loc[ind,'Name']='Light GBM'\n",
    "        if check==1:\n",
    "            df['model'][ind]=lgb.LGBMClassifier(boosting_type='gbdt',class_weight='balanced',learning_rate=0.1,n_estimators=100,random_state=1,subsample=1.0,num_leaves=31,max_depth=16,objective='binary')\n",
    "        elif check==0:\n",
    "            df['model'][ind]=lgb.LGBMClassifier(boosting_type='gbdt',class_weight='balanced',learning_rate=0.1,n_estimators=100,random_state=1,subsample=1.0,num_leaves=31,max_depth=16,objective='multiclass',num_class=len(priorList),metric='multi_logloss')\n",
    "        df.loc[ind,'param']= str(best)\n",
    "        Start=time.time()\n",
    "        if check==1:\n",
    "            df.loc[ind,'model'].fit(X_train, y_train,eval_metric=\"logloss\", eval_set=eval_set,early_stopping_rounds=30,verbose=False)\n",
    "        elif check==0:\n",
    "            df.loc[ind,'model'].fit(X_train, y_train,eval_metric=\"multi_logloss\", eval_set=eval_set,early_stopping_rounds=30,verbose=False)\n",
    "        lightgbm_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, lightgbm_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, lightgbm_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, lightgbm_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, lightgbm_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, lightgbm_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, lightgbm_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, lightgbm_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, lightgbm_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, lightgbm_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, lightgbm_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "        print(\"LGBM val done\")\n",
    "        ind=ind+1\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##Random forest\n",
    "        ########################################################################################################\n",
    "        df.loc[ind,'Name']='Random Forest'\n",
    "        df['model'][ind]=RandomForestClassifier(n_estimators=100,max_depth=16,class_weight='balanced')\n",
    "        df.loc[ind,'param']= str(best)\n",
    "        Start=time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        randomforest_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, randomforest_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, randomforest_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, randomforest_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, randomforest_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, randomforest_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, randomforest_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, randomforest_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, randomforest_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, randomforest_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, randomforest_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "        print(\"RF val done\")\n",
    "        ind=ind+1\n",
    "      \n",
    "        ########################################################################################################\n",
    "        \n",
    "        \n",
    "        ##ExtraTreesClassifier(2) Finding out accuracy on the test dataset\n",
    "        ########################################################################################################\n",
    "        df.loc[ind,'Name']='Extra Trees Classifier'\n",
    "        df['model'][ind]=ExtraTreesClassifier(n_estimators=100,max_depth=16,class_weight='balanced')\n",
    "        df.loc[ind,'param']=str(best)\n",
    "        Start=time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        extra_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, extra_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, extra_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, extra_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, extra_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, extra_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, extra_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, extra_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, extra_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, extra_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, extra_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "        print(\"ET val done\")\n",
    "        ind=ind+1\n",
    "        #########################################################################################################\n",
    "        \n",
    "        #NaiveBayes\n",
    "        ########################################################################################################\n",
    "      \n",
    "        if(flag == 1):\n",
    "            best = {'priors': priorList}\n",
    "            df.loc[ind,'Name']='Naive Bayes'\n",
    "            df.loc[ind,'model']=GaussianNB(priors = priorList)\n",
    "            df.loc[ind,'param']=str(best)\n",
    "            Start=time.time()\n",
    "            df.loc[ind,'model'].fit(X_train, y_train)\n",
    "            naive_pred = df.loc[ind,'model'].predict(X_test)\n",
    "            End=time.time()\n",
    "            df.loc[ind,'accuracy']=accuracy_score(y_test, naive_pred)*100\n",
    "            df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, naive_pred))))\n",
    "            df.loc[ind, 'Precision']=precision_score(y_test, naive_pred,average='weighted')\n",
    "            df.loc[ind, 'Recall']=recall_score(y_test, naive_pred,average='weighted')\n",
    "            df.loc[ind, 'F1']=f1_score(y_test, naive_pred,average='weighted')\n",
    "            if check==1:\n",
    "                df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, naive_pred,average='weighted')\n",
    "            #elif check==0:\n",
    "                #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, naive_pred,average='weighted',multi_class='ovo')\n",
    "            df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, naive_pred)\n",
    "            df.loc[ind, 'MCC']=matthews_corrcoef(y_test, naive_pred)\n",
    "            #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, naive_pred)\n",
    "            df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "            print(\"Naive Bayes done\")\n",
    "            ind=ind+1\n",
    "        \n",
    "        \n",
    "        #Logistic Regression\n",
    "        ##########################################################################################################\n",
    "        \n",
    "        df.loc[ind,'Name']='Logistic Regression'\n",
    "        df.loc[ind,'model']=LogisticRegression(class_weight='balanced',solver='saga',penalty='l2',random_state=1,max_iter=1000,multi_class ='auto')\n",
    "        df.loc[ind,'param']=\"\"\n",
    "        Start=time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        log_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, log_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, log_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, log_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, log_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, log_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, log_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, log_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, log_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, log_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, log_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "        print(\"LR val done\")\n",
    "        ind=ind+1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Neural net\n",
    "        ########################################################################################################\n",
    "      \n",
    "        if(flag == 1):\n",
    "            best={'hidden_layer_sizes':(50,),'solver':'sgd','learning_rate':'adaptive','max_iter':1000,'early_stopping':True}\n",
    "            df.loc[ind,'Name']='Neural Net'\n",
    "            df.loc[ind,'model']=MLPClassifier(**best)\n",
    "            df.loc[ind,'param']=str(best)\n",
    "            Start=time.time()\n",
    "            df.loc[ind,'model'].fit(X_train, y_train)\n",
    "            neural_pred = df.loc[ind,'model'].predict(X_test)\n",
    "            End=time.time()\n",
    "            df.loc[ind,'accuracy']=accuracy_score(y_test, neural_pred)*100\n",
    "            df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, neural_pred))))\n",
    "            df.loc[ind, 'Precision']=precision_score(y_test, neural_pred,average='weighted')\n",
    "            df.loc[ind, 'Recall']=recall_score(y_test, neural_pred,average='weighted')\n",
    "            df.loc[ind, 'F1']=f1_score(y_test, neural_pred,average='weighted')\n",
    "            if check==1:\n",
    "                df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, neural_pred,average='weighted')\n",
    "            #elif check==0:\n",
    "                #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, neural_pred,average='weighted',multi_class='ovo')\n",
    "            df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, neural_pred)\n",
    "            df.loc[ind, 'MCC']=matthews_corrcoef(y_test, neural_pred)\n",
    "            #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, neural_pred)\n",
    "            df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "            print(\"NN done\")\n",
    "            ind=ind+1\n",
    "            \n",
    "        \n",
    "        #SVC\n",
    "        #########################################################################################################\n",
    "            \n",
    "        df.loc[ind,'Name']='Support Vector Machine'\n",
    "        df.loc[ind,'model']= svm.SVC(kernel='linear',max_iter=1000,class_weight='balanced',probability=True,random_state=1)\n",
    "        df.loc[ind,'param']= str(best)\n",
    "        Start=time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        support_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, support_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, support_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, support_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, support_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, support_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, support_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, support_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, support_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, support_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, support_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "        print(\"SVC val done \")\n",
    "        ind=ind+1\n",
    "        \n",
    "        \n",
    "      elif q_s == False:\n",
    "        ind=0 \n",
    "        #XGBoost   \n",
    "        #########################################################################################################################\n",
    "        ##XGBoost(1) Finding Best hyperparamter using Bayesian Hyperparameter Optimization\n",
    "        ########################################################################################################\n",
    "        def objective(params):\n",
    "              print(params)\n",
    "              xg = xgb.XGBClassifier(**params)\n",
    "              result=cross_val_score(xg,X=X_train,y=y_train,cv=CV,scoring='accuracy',error_score=np.nan,n_jobs=6)\n",
    "              print(\"XGB train done\")\n",
    "              print(result.min()*100)\n",
    "              return (1-result.min())\n",
    "    \n",
    "        sample_weight = compute_sample_weight('balanced', y_train)   \n",
    "        Space = {\n",
    "              'n_estimators': 100, #scope.int(hp.quniform('n_estimators', 50,500,50)),\n",
    "              'eta': hp.uniform('eta', 0.01,0.2 ),\n",
    "              'max_depth': 16, #scope.int(hp.quniform('max_depth',2,16,1 )),\n",
    "              'min_child_weight':  scope.int(hp.quniform('min_child_weight',1,15,1 )),\n",
    "              'colsample_bytree': hp.uniform('colsample_bytree', 0.2,1.0 ),\n",
    "              'gamma': scope.int(hp.quniform('gamma', 0,15,1)),\n",
    "              'subsample': hp.uniform('subsample',  0.2,1.0  ),\n",
    "              # 'sample_weight':sample_weight\n",
    "              }\n",
    "        if check ==1:\n",
    "            Space['eval_metric'] = 'logloss'\n",
    "            if myval >2:\n",
    "                Space['scale_pos_weight'] = hp.choice('scale_pos_weight',[1,myval-1,myval,myval+1])\n",
    "            else:\n",
    "                Space['scale_pos_weight'] = hp.choice('scale_pos_weight',[1,myval])\n",
    "        elif check==0:\n",
    "            Space['eval_metric'] = 'mlogloss'\n",
    "            Space['objective'] = 'multi:softmax'\n",
    "            Space['num_class'] = len(priorList)\n",
    "\n",
    "      \n",
    "        bayes_trials = Trials()\n",
    "        print(\"Moving into HyperOp\")\n",
    "        best = fmin(fn=objective, space = Space, algo = hyperopt.tpe.suggest,max_evals=MAX_EVALS, trials = bayes_trials)\n",
    "        print(\"HyperOP done for XGB\")\n",
    "        \n",
    "        best['n_estimators']=100 #int(best['n_estimators'])\n",
    "        best['max_depth']=20 #int(best['max_depth'])\n",
    "        best['min_child_weight']=int(best['min_child_weight'])\n",
    "        best['gamma'] = int(best['gamma'])\n",
    "        if check==1:\n",
    "             best['eval_metric']='logloss'\n",
    "        elif check==0:\n",
    "             best['eval_metric']='mlogloss'\n",
    "             best['objective'] = 'multi:softmax'\n",
    "      \n",
    "        best['subsample'] = float(best['subsample'])\n",
    "        if check ==1:\n",
    "            if myval >2:\n",
    "                wea = [1,myval-1,myval,myval+1]\n",
    "                best['scale_pos_weight'] = wea[best['scale_pos_weight']]\n",
    "            else:\n",
    "                wea = [1,myval]\n",
    "                best['scale_pos_weight'] = wea[best['scale_pos_weight']]\n",
    "        # best['sample_weight']=sample_weight\n",
    "        print('XGB done')\n",
    "        ########################################################################################################\n",
    "      \n",
    "\n",
    "        ##XGBoost(2) Finding out accuracy on the test dataset\n",
    "        ########################################################################################################\n",
    "        df.loc[ind,'Name']='XGBoost'\n",
    "        df.loc[ind,'model']=xgb.XGBClassifier(**best)\n",
    "        df.loc[ind,'param']=str(best)\n",
    "        Start=time.time()\n",
    "        eval_set = [(X_test, y_test)]\n",
    "        if check ==1:\n",
    "            df.loc[ind,'model'].fit(X_train, y_train, eval_metric=\"logloss\",early_stopping_rounds=30, eval_set=eval_set,verbose=False)\n",
    "        elif check==0:\n",
    "            df.loc[ind,'model'].fit(X_train, y_train,sample_weight = w_array,early_stopping_rounds=30, eval_metric=\"mlogloss\", eval_set=eval_set,verbose=False)\n",
    "        \n",
    "        xgb_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, xgb_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, xgb_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, xgb_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, xgb_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, xgb_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, xgb_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, xgb_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, xgb_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, xgb_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, xgb_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)       \n",
    "        print(\"XGB val done\")\n",
    "        ind=ind+1\n",
    "        ########################################################################################################\n",
    "        \n",
    "        #Catboost\n",
    "        #########################################################################################################################\n",
    "        df.loc[ind,'Name']='CatBoost'\n",
    "        if check==1:\n",
    "            df.loc[ind,'model']=cb.CatBoostClassifier(depth=10,iterations=1000,learning_rate=0.1,rsm=1.0,auto_class_weights=\"Balanced\")\n",
    "        elif check==0:\n",
    "            df.loc[ind,'model']=cb.CatBoostClassifier(depth=10,iterations=1000,learning_rate=0.1,rsm=1.0,auto_class_weights=\"Balanced\",loss_function='MultiClass')\n",
    "\n",
    "        df.loc[ind,'param']=str(best)\n",
    "        Start=time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train,eval_set=eval_set,verbose=False)\n",
    "        catboost_pred = df.loc[ind,'model'].predict(X_test).tolist()\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, catboost_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, catboost_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, catboost_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, catboost_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, catboost_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, catboost_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, catboost_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, catboost_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, catboost_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, catboost_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "        print(\"CAT val done\")\n",
    "        ind=ind+1\n",
    "        ########################################################################################################\n",
    "        \n",
    "        \n",
    "        #LightGBM(1) Finding Best hyperparamter using Bayesian Hyperparameter Optimization\n",
    "        ########################################################################################################\n",
    "        \n",
    "        \n",
    "        def objective(params):\n",
    "            print('\\n',params)\n",
    "            lb = lgb.LGBMClassifier(**params)\n",
    "            result = cross_val_score(lb,X=X_train,y=y_train,cv=CV,scoring='accuracy',error_score=np.nan,n_jobs=6)\n",
    "            print(\"LGBM train done\")\n",
    "            print(\"\\n\",result.min()*100)\n",
    "            return (1-result.min())\n",
    "    \n",
    "    \n",
    "        Space = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'learning_rate': hp.uniform('learning_rate',0.01,0.2),\n",
    "                'class_weight': 'balanced',\n",
    "                'n_estimators': 100, #scope.int(hp.quniform('n_estimators',50,1250,75)),\n",
    "                'random_state':1,\n",
    "                'subsample': hp.uniform('subsample',  0.1,1.0  ),\n",
    "                'num_leaves': scope.int(hp.quniform('num_leaves',29,43,1)),\n",
    "                'max_depth': 16, # scope.int(hp.quniform('max_depth',2,16,1 )),\n",
    "                'min_child_weight':  scope.int(hp.quniform('min_child_weight',1,16,1 ))\n",
    "              }\n",
    "        \n",
    "        if check==1:\n",
    "            Space['objective'] = 'binary'\n",
    "        elif check==0:\n",
    "            Space['objective'] = 'multiclass'\n",
    "            Space['num_class'] = len(priorList)\n",
    "            Space['metric'] = 'multi_logloss'\n",
    "        \n",
    "        bayes_trials = Trials()\n",
    "        print(\"Moving into HyperOp\")\n",
    "        best = fmin(fn=objective, space = Space, algo = hyperopt.tpe.suggest,max_evals=MAX_EVALS, trials = bayes_trials)\n",
    "        print(\"HyperOP done for LGBM\")\n",
    "      \n",
    "        best['boosting_type'] = 'gbdt'\n",
    "        best['learning_rate'] = float(best['learning_rate'])\n",
    "        best['class_weight'] = 'balanced'\n",
    "        best['n_estimators'] = 100 #int(best['n_estimators'])\n",
    "        best['random_state'] = 1\n",
    "        best['subsample'] = float(best['subsample'])\n",
    "        best['num_leaves'] = int(best['num_leaves'])\n",
    "        best['min_child_weight']=int(best['min_child_weight'])\n",
    "        best['max_depth'] = 16 #int(best['max_depth'])\n",
    "        if check==1:\n",
    "            best['objective'] = 'binary'\n",
    "        elif check==0:\n",
    "            best['objective'] = 'multiclass'\n",
    "            best['num_class'] = len(priorList)\n",
    "            best['metric'] = 'multi_logloss'\n",
    "      \n",
    "        print(\"LGBM done\")\n",
    "        \n",
    "        ########################################################################################################\n",
    "        ##LGBM(2) Finding out accuracy on the test dataset\n",
    "        ########################################################################################################\n",
    "        eval_set = [(X_test, y_test)]\n",
    "        df.loc[ind,'Name']='Light GBM'\n",
    "        df['model'][ind]=lgb.LGBMClassifier(**best)\n",
    "        df.loc[ind,'param']= str(best)\n",
    "        Start=time.time()\n",
    "        if check==1:\n",
    "            df.loc[ind,'model'].fit(X_train, y_train,eval_metric=\"logloss\", eval_set=eval_set,early_stopping_rounds=30,verbose=False)\n",
    "        elif check==0:\n",
    "            df.loc[ind,'model'].fit(X_train, y_train,eval_metric=\"multi_logloss\", eval_set=eval_set,early_stopping_rounds=30,verbose=False)\n",
    "        lightgbm_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, lightgbm_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, lightgbm_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, lightgbm_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, lightgbm_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, lightgbm_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, lightgbm_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, lightgbm_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, lightgbm_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, lightgbm_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, lightgbm_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "        print(\"LGBM val done\")\n",
    "        ind=ind+1\n",
    "    \n",
    "      \n",
    "      \n",
    "        #Random Forest\n",
    "        ########################################################################################################\n",
    "        ##Random Forest(1) Finding Best hyperparamter using Bayesian Hyperparameter Optimization\n",
    "        ########################################################################################################\n",
    "        def objective(params):\n",
    "            print(params)\n",
    "            rf = RandomForestClassifier(**params)\n",
    "            result=cross_val_score(rf,X=X_train,y=y_train,cv=CV,scoring='accuracy',error_score=np.nan,n_jobs=6)\n",
    "            print(\"RF train done\")\n",
    "            print(result.min()*100)\n",
    "            return (1-result.min())\n",
    "              \n",
    "        DSpace = {\n",
    "                  'n_estimators': 100, # scope.int(hp.quniform('n_estimators', 100, 1200,50)),\n",
    "                  \"max_depth\": 16, # scope.int(hp.quniform('max_depth',2,20,1)),\n",
    "                  'max_features': hp.choice('max_features',['auto', 'sqrt','log2']),\n",
    "                  'min_samples_split': scope.int(hp.quniform('min_samples_split',2,15,1)),\n",
    "                  'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1,20,1)),\n",
    "                  'oob_score':False,\n",
    "                  'bootstrap':  hp.choice('bootstrap',[True, False]),\n",
    "                  'class_weight':'balanced'\n",
    "                  }                                                           \n",
    "      \n",
    "        bayes_trials = Trials()\n",
    "        print(\"Moving into HyperOp\")\n",
    "        try:\n",
    "            best = fmin(fn = objective, space = DSpace, algo = hyperopt.tpe.suggest,max_evals = MAX_EVALS, trials = bayes_trials)\n",
    "            print(\"HyperOP done for RF\")\n",
    "        except:\n",
    "            print(\"Hyperparameter tuning failed\")\n",
    "            best.clear()\n",
    "            best['class_weight']='balanced'\n",
    "        else: \n",
    "            best['n_estimators']=100 #int(best['n_estimators'])\n",
    "            best['max_depth']= 16 #int(best['max_depth'])\n",
    "            best['min_samples_split']=int(best['min_samples_split'])\n",
    "            best['min_samples_leaf']=int(best['min_samples_leaf'])\n",
    "            fea=['auto', 'sqrt','log2']\n",
    "            best['max_features']=fea[best['max_features']]\n",
    "            best['oob_score']= False\n",
    "            boot=[True, False]\n",
    "            best['bootstrap']=boot[best['bootstrap']]\n",
    "            best['class_weight']='balanced'\n",
    "            print(\"HyperOP done for RF\")\n",
    "        \n",
    "\n",
    "        print(\"RF done\")\n",
    "        ########################################################################################################\n",
    "      \n",
    "      \n",
    "\n",
    "        ##Random forest(2) Finding out accuracy on the test dataset\n",
    "        ########################################################################################################\n",
    "        et_dict = best.copy()\n",
    "        df.loc[ind,'Name']='Random Forest'\n",
    "        df['model'][ind]=RandomForestClassifier(**best)\n",
    "        df.loc[ind,'param']= str(best)\n",
    "        Start=time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        randomforest_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, randomforest_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, randomforest_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, randomforest_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, randomforest_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, randomforest_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, randomforest_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, randomforest_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, randomforest_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, randomforest_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, randomforest_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "        print(\"RF val done\")\n",
    "        ind=ind+1\n",
    "      \n",
    "        ########################################################################################################\n",
    "        \n",
    "        #ExtraTreesClassifier\n",
    "        ########################################################################################################\n",
    "        df.loc[ind,'Name']='Extra Trees Classifier'\n",
    "        df['model'][ind]=ExtraTreesClassifier(**et_dict)\n",
    "        df.loc[ind,'param']=str(et_dict)\n",
    "        Start=time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        extra_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, extra_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, extra_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, extra_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, extra_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, extra_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, extra_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, extra_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, extra_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, extra_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, extra_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "        print(\"ET val done\")\n",
    "        ind=ind+1\n",
    "        #########################################################################################################\n",
    "      \n",
    "        #NaiveBayes\n",
    "        ########################################################################################################\n",
    "      \n",
    "        if(flag == 1):\n",
    "            best = {'priors': priorList}\n",
    "            df.loc[ind,'Name']='Naive Bayes'\n",
    "            df.loc[ind,'model']=GaussianNB(priors = priorList)\n",
    "            df.loc[ind,'param']=str(best)\n",
    "            Start=time.time()\n",
    "            df.loc[ind,'model'].fit(X_train, y_train)\n",
    "            naive_pred = df.loc[ind,'model'].predict(X_test)\n",
    "            End=time.time()\n",
    "            df.loc[ind,'accuracy']=accuracy_score(y_test, naive_pred)*100\n",
    "            df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, naive_pred))))\n",
    "            df.loc[ind, 'Precision']=precision_score(y_test, naive_pred,average='weighted')\n",
    "            df.loc[ind, 'Recall']=recall_score(y_test, naive_pred,average='weighted')\n",
    "            df.loc[ind, 'F1']=f1_score(y_test, naive_pred,average='weighted')\n",
    "            if check==1:\n",
    "                df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, naive_pred,average='weighted')\n",
    "            #elif check==0:\n",
    "                #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, naive_pred,average='weighted',multi_class='ovo')\n",
    "            df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, naive_pred)\n",
    "            df.loc[ind, 'MCC']=matthews_corrcoef(y_test, naive_pred)\n",
    "            #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, naive_pred)\n",
    "            df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "            print(\"Naive Bayes done\")\n",
    "            ind=ind+1\n",
    "      \n",
    "    \n",
    "        #Logistic regression\n",
    "        ########################################################################################################\n",
    "        df.loc[ind,'Name']='Logistic Regression'\n",
    "        df.loc[ind,'model']=LogisticRegression(class_weight='balanced',solver='saga',penalty='l2',random_state=1,max_iter=1000,multi_class ='auto')\n",
    "        df.loc[ind,'param']=\"\"\n",
    "        Start=time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        log_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, log_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, log_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, log_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, log_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, log_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, log_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, log_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, log_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, log_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, log_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "        print(\"LR val done\")\n",
    "        ind=ind+1\n",
    "      \n",
    "        \n",
    "        #Neural net\n",
    "        ########################################################################################################\n",
    "      \n",
    "        if(flag == 1):\n",
    "                best={'hidden_layer_sizes':(50,),'solver':'sgd','learning_rate':'adaptive','max_iter':1000,'early_stopping':True}\n",
    "                df.loc[ind,'Name']='Neural Net'\n",
    "                df.loc[ind,'model']=MLPClassifier(**best)\n",
    "                df.loc[ind,'param']=str(best)\n",
    "                Start=time.time()\n",
    "                df.loc[ind,'model'].fit(X_train, y_train)\n",
    "                neural_pred = df.loc[ind,'model'].predict(X_test)\n",
    "                End=time.time()\n",
    "                df.loc[ind,'accuracy']=accuracy_score(y_test, neural_pred)*100\n",
    "                df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, neural_pred))))\n",
    "                df.loc[ind, 'Precision']=precision_score(y_test, neural_pred,average='weighted')\n",
    "                df.loc[ind, 'Recall']=recall_score(y_test, neural_pred,average='weighted')\n",
    "                df.loc[ind, 'F1']=f1_score(y_test, neural_pred,average='weighted')\n",
    "                if check==1:\n",
    "                    df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, neural_pred,average='weighted')\n",
    "                #elif check==0:\n",
    "                    #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, neural_pred,average='weighted',multi_class='ovo')\n",
    "                df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, neural_pred)\n",
    "                df.loc[ind, 'MCC']=matthews_corrcoef(y_test, neural_pred)\n",
    "                #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, neural_pred)\n",
    "                df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "                print(\"NN done\")\n",
    "                ind=ind+1\n",
    "    \n",
    "        #Support Vector Machine(linear)\n",
    "        ########################################################################################################\n",
    "            \n",
    "        df.loc[ind,'Name']='Support Vector Machine'\n",
    "        df.loc[ind,'model']= svm.SVC(kernel='linear',max_iter=1000,class_weight='balanced',probability=True,random_state=1)\n",
    "        df.loc[ind,'param']= str(best)\n",
    "        Start=time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        support_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=accuracy_score(y_test, support_pred)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, support_pred))))\n",
    "        df.loc[ind, 'Precision']=precision_score(y_test, support_pred,average='weighted')\n",
    "        df.loc[ind, 'Recall']=recall_score(y_test, support_pred,average='weighted')\n",
    "        df.loc[ind, 'F1']=f1_score(y_test, support_pred,average='weighted')\n",
    "        if check==1:\n",
    "            df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, support_pred,average='weighted')\n",
    "        #elif check==0:\n",
    "            #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, support_pred,average='weighted',multi_class='ovo')\n",
    "        df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, support_pred)\n",
    "        df.loc[ind, 'MCC']=matthews_corrcoef(y_test, support_pred)\n",
    "        #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, support_pred)\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "        print(\"SVC val done \")\n",
    "        ind=ind+1\n",
    "      \n",
    "      \n",
    "      \n",
    "      #Ensemble\n",
    "      ########################################################################################################\n",
    "      ##Ensemble(1) Finding all possible combination of above model and find out the best combination based on testing data accuracy\n",
    "      ########################################################################################################\n",
    "      lev=len(np.unique(y_test))\n",
    "      arr1=np.empty((len(y_test),lev,0))\n",
    "      for i in range(0,len(df)):\n",
    "          arr1=np.dstack((arr1,df.loc[i,'model'].predict_proba(X_test)))\n",
    "\n",
    "      max_f1=0\n",
    "      max_seq=0\n",
    "      for i in range(2,len(df)+1):\n",
    "          comb=list(combinations(enumerate(np.rollaxis(arr1,axis=2,start=0)), i))\n",
    "          for j in range(0,len(comb)):\n",
    "              m=np.empty((len(y_test),lev,0))\n",
    "              for x in range(0,len(comb[j])):\n",
    "                  m=np.dstack((m,comb[j][x][1]))\n",
    "              arr=np.mean(m,axis=2)\n",
    "              clas=np.argmax(arr,axis=1)\n",
    "              f1=f1_score(y_test, clas,average='weighted')*100\n",
    "              seq=np.array(comb[j])[:,0]\n",
    "              if f1>max_f1:\n",
    "                  max_f1=f1\n",
    "                  max_seq=seq\n",
    "                \n",
    "      print(\"this is what you are printing\",max_seq) \n",
    "      ########################################################################################################\n",
    "\n",
    "      ##Ensemble(2) List of the best combination from the above method\n",
    "      ########################################################################################################  \n",
    "      name=''\n",
    "      df_en=pd.DataFrame(index = range(1000), columns=['Name','model'])\n",
    "      for i in range(0,len(max_seq)):\n",
    "          df_en.at[i,'Name']= df.at[max_seq[i],'Name']\n",
    "          val = df.at[max_seq[i],'model']\n",
    "          df_en['model'][i] = val\n",
    "          name=name+df['Name'][max_seq[i]]+'+'\n",
    "      \n",
    "      df_en.dropna(axis=0,inplace=True)\n",
    "      ########################################################################################################\n",
    "      \n",
    "      \n",
    "      ##Ensemble(3) Making an esemble model of the best combination\n",
    "      ########################################################################################################\n",
    "      df.loc[ind,'Name']=('Ensemble '+name)[:-1]\n",
    "      df.loc[ind,'model']=VotingClassifier(df_en.values, voting='soft',n_jobs=-1)\n",
    "      df.loc[ind,'param']=\"Default\"\n",
    "      Start=time.time()\n",
    "      df.loc[ind,'model'].fit(X_train, y_train)\n",
    "      ensemble_pred = df.loc[ind,'model'].predict(X_test)\n",
    "      End=time.time()\n",
    "      df.loc[ind,'accuracy']=accuracy_score(y_test, ensemble_pred)*100\n",
    "      df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(accuracy_score(y_test, ensemble_pred))))\n",
    "      df.loc[ind, 'Precision']=precision_score(y_test, ensemble_pred,average='weighted')\n",
    "      df.loc[ind, 'Recall']=recall_score(y_test, ensemble_pred,average='weighted')\n",
    "      df.loc[ind, 'F1']=f1_score(y_test, ensemble_pred,average='weighted')\n",
    "      if check==1:\n",
    "          df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, ensemble_pred,average='weighted')\n",
    "      #elif check==0:\n",
    "          #df.loc[ind, 'ROC_AUC_score']=roc_auc_score(y_test, ensemble_pred,average='weighted',multi_class='ovo')\n",
    "      df.loc[ind, 'Kappa']=cohen_kappa_score(y_test, ensemble_pred)\n",
    "      df.loc[ind, 'MCC']=matthews_corrcoef(y_test, ensemble_pred)\n",
    "      #df.loc[ind, 'KS_statistic'],df.loc[ind, 'KS_p-value']=ks_2samp(y_test, ensemble_pred)\n",
    "      df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "      ind=ind+1\n",
    "\n",
    "      ##Best Model\n",
    "      ########################################################################################################\n",
    "      best_info=df.sort_values('F1',ignore_index=True,ascending=False).loc[0,:]\n",
    "      best_name=best_info['Name']\n",
    "      best_mod=best_info['model']\n",
    "      best_acc=best_info['accuracy']\n",
    "      best_param=best_info['param']\n",
    "      ########################################################################################################    \n",
    "    \n",
    "      joblib.dump(best_info,'best_info')\n",
    "        \n",
    "      return best_name,best_mod, best_acc, best_param,df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjtHOrj3W-qo"
   },
   "source": [
    "# REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AWTZ0jC_W-qo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import numpy as np\n",
    "import random\n",
    "from pprint import pprint\n",
    "from itertools import combinations\n",
    "import ast # ast.literal_eval(str(best))\n",
    "from time import process_time \n",
    "import time\n",
    "from math import sqrt\n",
    "from decimal import Decimal\n",
    "\n",
    "# Model\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "#Hyperopt\n",
    "import hyperopt\n",
    "from hyperopt import *\n",
    "from hyperopt.pyll.base import scope\n",
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "\n",
    "\n",
    "#sklearn library\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from RegscorePy import aic,bic\n",
    "\n",
    "  ###############################################################################################################################\n",
    "class Regression:\n",
    "\n",
    "  #This funciton takes input of training and testing datasets and give out the best model's Name, model with best parameter(can be used directly to score data using 'predcit' function), accuracy on the test dataset and parameters (not usefful)\n",
    "  ###############################################################################################################################\n",
    "  def best_model_reg(self,X_train , X_test, y_train, y_test,q_s,MAX_EVALS=15,CV=5):\n",
    "      df=pd.DataFrame()\n",
    "      print(\"The value of Q_S is \",q_s)\n",
    "      \n",
    "      \n",
    "      \n",
    "        \n",
    "      if q_s ==True:  #QUICK RESULTS\n",
    "        ind=0\n",
    "        best = {}\n",
    "        #XGBoost\n",
    "        #######################################################################\n",
    "        df.loc[ind,'Name']='XGBoost'\n",
    "        df.loc[ind,'model']=xgb.XGBRegressor(n_estimators=100,eta=0.1,max_depth=16,min_child_weight=2,gamma=5,subsample=0.1,objective=\"reg:squarederror\",eval_metric='rmse')\n",
    "        df.loc[ind,'param']=str(best)\n",
    "        Start = time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        xgb_reg_prob1 = df.loc[ind,'model'].predict(X_test).tolist()\n",
    "        print(type(xgb_reg_prob1))\n",
    "        End = time.time()\n",
    "        df.loc[ind,'accuracy']=r2_score(y_test, xgb_reg_prob1)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, xgb_reg_prob1))))\n",
    "        df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, xgb_reg_prob1))\n",
    "        df.loc[ind,'MSE'] = mean_squared_error(y_test, xgb_reg_prob1)\n",
    "        df.loc[ind,'MAE']=mean_absolute_error(y_test, xgb_reg_prob1)\n",
    "        #df.loc[ind,'AIC']=aic.aic(y_test, xgb_reg_prob1,X_train.shape[1])\n",
    "        #print(\"aic done\")\n",
    "        df.loc[ind,'BIC']=bic.bic(y_test, xgb_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "      \n",
    "        print(\"XGB Validation done\")\n",
    "        ind=ind+1\n",
    "        ########################################################################################################\n",
    "    \n",
    "        ##Catboost\n",
    "        ########################################################################################################\n",
    "        df.loc[ind,'Name']='CatBoost'\n",
    "        df.loc[ind,'model']=cb.CatBoostRegressor(depth=10,iterations=1000,learning_rate=0.1,rsm=1.0,silent=True)\n",
    "        df.loc[ind,'param']=str(best)\n",
    "        Start = time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        cat_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "        End = time.time()\n",
    "        df.loc[ind,'accuracy']=r2_score(y_test, cat_reg_prob1)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, cat_reg_prob1))))\n",
    "        df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, cat_reg_prob1))\n",
    "        df.loc[ind,'MSE'] = mean_squared_error(y_test, cat_reg_prob1)\n",
    "        df.loc[ind,'MAE']=mean_absolute_error(y_test, cat_reg_prob1)\n",
    "        #df.loc[ind,'AIC']=aic.aic(y_test, cat_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'BIC']=bic.bic(y_test, cat_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)      \n",
    "        print(\"CAT Validation done\")\n",
    "        ind=ind+1\n",
    "        ########################################################################################################\n",
    "        \n",
    "          \n",
    "        ##LGBM\n",
    "        ########################################################################################################\n",
    "        eval_set = [(X_test, y_test)]\n",
    "        df.loc[ind,'Name']='Light GBM'\n",
    "        df['model'][ind]=lgb.LGBMRegressor(boosting_type='gbdt',learning_rate=0.1,n_estimators=100,random_state=1,subsample=1.0,num_leaves=31,max_depth=16)\n",
    "        df.loc[ind,'param']= str(best)\n",
    "        Start=time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train,verbose=False)\n",
    "        lightgbm_pred = df.loc[ind,'model'].predict(X_test)\n",
    "        End=time.time()\n",
    "        df.loc[ind,'accuracy']=r2_score(y_test, cat_reg_prob1)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, cat_reg_prob1))))\n",
    "        df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, cat_reg_prob1))\n",
    "        df.loc[ind,'MSE'] = mean_squared_error(y_test, cat_reg_prob1)\n",
    "        df.loc[ind,'MAE']=mean_absolute_error(y_test, cat_reg_prob1)\n",
    "        #df.loc[ind,'AIC']=aic.aic(y_test, cat_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'BIC']=bic.bic(y_test, cat_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)   \n",
    "        print(\"LGBM val done\")\n",
    "        ind=ind+1\n",
    "        ########################################################################################################\n",
    "        \n",
    "        \n",
    "        ##Random forest\n",
    "        ########################################################################################################\n",
    "        df.loc[ind,'Name']='Random Forest'\n",
    "        df['model'][ind]=RandomForestRegressor(n_estimators=100,max_depth=20)\n",
    "        df.loc[ind,'param']=str(best)\n",
    "        Start = time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        random_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "        End = time.time()\n",
    "        df.loc[ind,'accuracy']=r2_score(y_test, random_reg_prob1)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, random_reg_prob1))))\n",
    "        df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, random_reg_prob1))\n",
    "        df.loc[ind,'MSE'] = mean_squared_error(y_test, random_reg_prob1)\n",
    "        df.loc[ind,'MAE']=mean_absolute_error(y_test, random_reg_prob1)\n",
    "        #df.loc[ind,'AIC']=aic.aic(y_test, random_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'BIC']=bic.bic(y_test, random_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)       \n",
    "        print(\"RF Validation done\")\n",
    "        ind=ind+1\n",
    "      \n",
    "        ########################################################################################################\n",
    "        \n",
    "        \n",
    "        ##ExtraTreesClassifier(2) Finding out accuracy on the test dataset\n",
    "        ########################################################################################################\n",
    "        df.loc[ind,'Name']='ExtraTrees Regressor'\n",
    "        df['model'][ind]=ExtraTreesRegressor(n_estimators=100,max_depth=20)\n",
    "        df.loc[ind,'param']=str(best)\n",
    "        Start = time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        extra_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "        End = time.time()\n",
    "        df.loc[ind,'accuracy']=r2_score(y_test, extra_reg_prob1)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, extra_reg_prob1))))\n",
    "        df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, extra_reg_prob1))\n",
    "        df.loc[ind,'MSE'] = mean_squared_error(y_test, extra_reg_prob1)\n",
    "        df.loc[ind,'MAE']=mean_absolute_error(y_test, extra_reg_prob1)\n",
    "        #df.loc[ind,'AIC']=aic.aic(y_test, extra_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'BIC']=bic.bic(y_test, extra_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)      \n",
    "        print(\"ET Validation done\")\n",
    "        ind=ind+1\n",
    "        #########################################################################################################\n",
    "        \n",
    "        \n",
    "        #Linear Regression\n",
    "        ##########################################################################################################\n",
    "      \n",
    "        df.loc[ind,'Name']='Linear Regression'\n",
    "        df.loc[ind,'model']=LinearRegression()\n",
    "        df.loc[ind,'param']=None\n",
    "        Start = time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        logr_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "        End = time.time()\n",
    "        df.loc[ind,'accuracy']=r2_score(y_test, logr_reg_prob1)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, logr_reg_prob1))))\n",
    "        df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, logr_reg_prob1))\n",
    "        df.loc[ind,'MSE'] = mean_squared_error(y_test, logr_reg_prob1)\n",
    "        df.loc[ind,'MAE']=mean_absolute_error(y_test, logr_reg_prob1)\n",
    "        #df.loc[ind,'AIC']=aic.aic(y_test, logr_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'BIC']=bic.bic(y_test, logr_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)   \n",
    "      \n",
    "        print(\"linear reg done\")\n",
    "        ind=ind+1\n",
    "        \n",
    "        #Ridge Regression\n",
    "        ##########################################################################################################\n",
    "        \n",
    "        df.loc[ind,'Name']='Ridge Regression'\n",
    "        df.loc[ind,'model']=Ridge()\n",
    "        df.loc[ind,'param']=None\n",
    "        Start = time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        ridge_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "        End = time.time()\n",
    "        df.loc[ind,'accuracy']=r2_score(y_test, ridge_reg_prob1)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, ridge_reg_prob1))))\n",
    "        df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, ridge_reg_prob1))\n",
    "        df.loc[ind,'MSE'] = mean_squared_error(y_test, ridge_reg_prob1)\n",
    "        df.loc[ind,'MAE']=mean_absolute_error(y_test, ridge_reg_prob1)\n",
    "        #df.loc[ind,'AIC']=aic.aic(y_test, ridge_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'BIC']=bic.bic(y_test, ridge_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)     \n",
    "        print(\"ridge reg done\")\n",
    "        ind=ind+1\n",
    "\n",
    "        #Neural net\n",
    "        ########################################################################################################\n",
    "      \n",
    "        best={'hidden_layer_sizes':(50,),'solver':'sgd','learning_rate':'adaptive','max_iter':1000,'early_stopping':True,'n_iter_no_change':30}\n",
    "        df.loc[ind,'Name']='Neural Net'\n",
    "        df.loc[ind,'model']=MLPRegressor(**best)\n",
    "        df.loc[ind,'param']=str(best)\n",
    "        Start = time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        mlpc_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "        End = time.time()\n",
    "        try:\n",
    "            df.loc[ind,'accuracy']=r2_score(y_test, mlpc_reg_prob1)*100\n",
    "        except:\n",
    "            print(\"Neural Net threw an error\")\n",
    "        else:\n",
    "            df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, mlpc_reg_prob1))))\n",
    "            df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, mlpc_reg_prob1))\n",
    "            df.loc[ind,'MSE'] = mean_squared_error(y_test, mlpc_reg_prob1)\n",
    "            df.loc[ind,'MAE']=mean_absolute_error(y_test, mlpc_reg_prob1)\n",
    "            #df.loc[ind,'AIC']=aic.aic(y_test, mlpc_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'BIC']=bic.bic(y_test, mlpc_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)     \n",
    "\n",
    "            print(\"neural net done\") \n",
    "            ind=ind+1\n",
    "        \n",
    "        #SVC\n",
    "        #########################################################################################################\n",
    "            \n",
    "        df.loc[ind,'Name']='Support Vector Machine'\n",
    "        df.loc[ind,'model']=svm.SVR(kernel='linear',max_iter=1000)\n",
    "        df.loc[ind,'param']=None\n",
    "        Start = time.time()\n",
    "        df.loc[ind,'model'].fit(X_train, y_train)\n",
    "        svc_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "        End = time.time()\n",
    "        df.loc[ind,'accuracy']=r2_score(y_test, svc_reg_prob1)*100\n",
    "        df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, svc_reg_prob1))))\n",
    "        df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, svc_reg_prob1))\n",
    "        df.loc[ind,'MSE'] = mean_squared_error(y_test, svc_reg_prob1)\n",
    "        df.loc[ind,'MAE']=mean_absolute_error(y_test, svc_reg_prob1)\n",
    "        #df.loc[ind,'AIC']=aic.aic(y_test, svc_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'BIC']=bic.bic(y_test, svc_reg_prob1,X_train.shape[1])\n",
    "        df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)      \n",
    "      \n",
    "        print(\"SVC done\")\n",
    "        ind=ind+1\n",
    "    \n",
    "      elif q_s==False:\n",
    "            ind = 0\n",
    "            #XGBoost\n",
    "            #########################################################################################################################\n",
    "            ##XGBoost(1) Finding Best hyperparamter using Bayesian Hyperparameter Optimization\n",
    "            ########################################################################################################\n",
    "            def objective(params):\n",
    "                  print(params)\n",
    "                  xg = xgb.XGBRegressor(**params)\n",
    "                  result=cross_val_score(xg,X=X_train,y=y_train,cv=CV,scoring='r2',error_score=np.nan,n_jobs=6)\n",
    "                  print(\"XGB Training Done\")\n",
    "                  return (1-result.min())\n",
    "      \n",
    "      \n",
    "            Space = {\n",
    "                  'n_estimators': 100, # scope.int(hp.quniform('n_estimators', 50,1250,75)),\n",
    "                  'eta': hp.uniform('eta', 0.01,0.2 ),\n",
    "                  'max_depth': 20, # scope.int(hp.quniform('max_depth',2,16,1 )),\n",
    "                  'min_child_weight':  scope.int(hp.quniform('min_child_weight',1,15,1 )),\n",
    "                  'colsample_bytree': hp.uniform('colsample_bytree', 0.2,1.0 ),\n",
    "                  'gamma': scope.int(hp.quniform('gamma', 0,15,1)),\n",
    "                  'eval_metric': 'rmse',\n",
    "                  'objective': 'reg:linear',\n",
    "                  'subsample': hp.uniform('subsample',  0.2,1.0  )\n",
    "              }\n",
    "      \n",
    "      \n",
    "            bayes_trials = Trials()\n",
    "            best = fmin(fn = objective, space = Space, algo = hyperopt.tpe.suggest,max_evals=MAX_EVALS, trials = bayes_trials)\n",
    "            print(\"XGB hyperop done\")\n",
    "      \n",
    "      \n",
    "            best['n_estimators']=100 #int(best['n_estimators'])\n",
    "            best['max_depth']=20 #int(best['max_depth'])\n",
    "            best['gamma'] = int(best['gamma'])\n",
    "            best['subsample']= float(best['subsample'])\n",
    "            best['min_child_weight']=int(best['min_child_weight'])\n",
    "            best['objective']='reg:squarederror'\n",
    "            best['eval_metric']='rmse'\n",
    "            ########################################################################################################\n",
    "      \n",
    "\n",
    "            ##XGBoost(2) Finding out accuracy on the test dataset\n",
    "            ########################################################################################################\n",
    "            eval_set = [(X_test, y_test)]\n",
    "            df.loc[ind,'Name']='XGBoost'\n",
    "            df.loc[ind,'model']=xgb.XGBRegressor(**best)\n",
    "            df.loc[ind,'param']=str(best)\n",
    "            Start = time.time()\n",
    "            df.loc[ind,'model'].fit(X_train, y_train,eval_metric=\"rmse\", eval_set=eval_set,early_stopping_rounds=30,verbose=False)\n",
    "            xgb_reg_prob1 = df.loc[ind,'model'].predict(X_test).tolist()\n",
    "            print(type(xgb_reg_prob1))\n",
    "            End = time.time()\n",
    "            df.loc[ind,'accuracy']=r2_score(y_test, xgb_reg_prob1)*100\n",
    "            df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, xgb_reg_prob1))))\n",
    "            df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, xgb_reg_prob1))\n",
    "            df.loc[ind,'MSE'] = mean_squared_error(y_test, xgb_reg_prob1)\n",
    "            df.loc[ind,'MAE']=mean_absolute_error(y_test, xgb_reg_prob1)\n",
    "            #df.loc[ind,'AIC']=aic.aic(y_test, xgb_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'BIC']=bic.bic(y_test, xgb_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)\n",
    "      \n",
    "            print(\"XGB Validation done\")\n",
    "            ind=ind+1\n",
    "            ########################################################################################################\n",
    "      \n",
    "      \n",
    "            #Catboost\n",
    "            #########################################################################################################################\n",
    "            ##Catboost \n",
    "            ########################################################################################################\n",
    "            df.loc[ind,'Name']='CatBoost'\n",
    "            df.loc[ind,'model']=cb.CatBoostRegressor(depth=10,iterations=1000,learning_rate=0.1,rsm=1.0,silent=True)\n",
    "            df.loc[ind,'param']=str(best)\n",
    "            Start = time.time()\n",
    "            df.loc[ind,'model'].fit(X_train, y_train)\n",
    "            cat_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "            End = time.time()\n",
    "            df.loc[ind,'accuracy']=r2_score(y_test, cat_reg_prob1)*100\n",
    "            df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, cat_reg_prob1))))\n",
    "            df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, cat_reg_prob1))\n",
    "            df.loc[ind,'MSE'] = mean_squared_error(y_test, cat_reg_prob1)\n",
    "            df.loc[ind,'MAE']=mean_absolute_error(y_test, cat_reg_prob1)\n",
    "            #df.loc[ind,'AIC']=aic.aic(y_test, cat_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'BIC']=bic.bic(y_test, cat_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)      \n",
    "            print(\"CAT Validation done\")\n",
    "            ind=ind+1\n",
    "            ########################################################################################################\n",
    "            \n",
    "            \n",
    "            #LightGBM\n",
    "            ########################################################################################################\n",
    "            ##LightGBM(1) Finding Best hyperparamter using Bayesian Hyperparameter Optimization\n",
    "            ########################################################################################################\n",
    "            \n",
    "            def objective(params):\n",
    "                  print(params)\n",
    "                  xg = lgb.LGBMRegressor(**params)\n",
    "                  result=cross_val_score(xg,X=X_train,y=y_train,cv=CV,scoring='r2',error_score=np.nan,n_jobs=6)\n",
    "                  print(\"XGB Training Done\")\n",
    "                  return (1-result.min())\n",
    "                \n",
    "            \n",
    "            Space = {\n",
    "                'boosting_type': 'gbdt',\n",
    "                'learning_rate': hp.uniform('learning_rate',0.01,0.2),\n",
    "                'n_estimators': 100, # scope.int(hp.quniform('n_estimators',50,1250,75)),\n",
    "                'random_state':1,\n",
    "                'subsample': hp.uniform('subsample',  0.1,1.0  ),\n",
    "                'num_leaves': scope.int(hp.quniform('num_leaves',29,43,1)),\n",
    "                'max_depth': 16, #scope.int(hp.quniform('max_depth',2,16,1 )),\n",
    "                'min_child_weight':  scope.int(hp.quniform('min_child_weight',1,16,1 ))\n",
    "              }\n",
    "            \n",
    "            bayes_trials = Trials()\n",
    "            print(\"Moving into HyperOp\")\n",
    "            best = fmin(fn=objective, space = Space, algo = hyperopt.tpe.suggest,max_evals=MAX_EVALS, trials = bayes_trials)\n",
    "            print(\"HyperOP done for LGBM\")\n",
    "            \n",
    "            best['boosting_type'] = 'gbdt'\n",
    "            best['learning_rate'] = float(best['learning_rate'])\n",
    "            best['n_estimators'] = 100 #int(best['n_estimators'])\n",
    "            best['random_state'] = 1\n",
    "            best['subsample'] = float(best['subsample'])\n",
    "            best['num_leaves'] = int(best['num_leaves'])\n",
    "            best['min_child_weight']=int(best['min_child_weight'])\n",
    "            best['max_depth'] = 16 #int(best['max_depth'])\n",
    "      \n",
    "            print(\"LGBM done\")\n",
    "      \n",
    "            ##LightGBM(2) Finding out accuracy on the test dataset\n",
    "            ########################################################################################################\n",
    "            eval_set = [(X_test, y_test)]\n",
    "            df.loc[ind,'Name']='Light GBM'\n",
    "            df['model'][ind]=lgb.LGBMRegressor(**best)\n",
    "            df.loc[ind,'param']= str(best)\n",
    "            Start=time.time()\n",
    "            df.loc[ind,'model'].fit(X_train, y_train,eval_metric=\"logloss\", eval_set=eval_set,early_stopping_rounds=30,verbose=False)\n",
    "            lightgbm_pred = df.loc[ind,'model'].predict(X_test)\n",
    "            End=time.time()\n",
    "            df.loc[ind,'accuracy']=r2_score(y_test, cat_reg_prob1)*100\n",
    "            df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, cat_reg_prob1))))\n",
    "            df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, cat_reg_prob1))\n",
    "            df.loc[ind,'MSE'] = mean_squared_error(y_test, cat_reg_prob1)\n",
    "            df.loc[ind,'MAE']=mean_absolute_error(y_test, cat_reg_prob1)\n",
    "            #df.loc[ind,'AIC']=aic.aic(y_test, cat_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'BIC']=bic.bic(y_test, cat_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)   \n",
    "            print(\"LGBM val done\")\n",
    "            ind=ind+1 \n",
    "            \n",
    "      \n",
    "            #Random forest\n",
    "            ######################################################################################################################### \n",
    "            ##Random forest(1) Finding Best hyperparamter using Bayesian Hyperparameter Optimization\n",
    "            ########################################################################################################\n",
    "            def objective(params):\n",
    "                  print(params)\n",
    "                  rf = RandomForestRegressor(**params)\n",
    "                  result=cross_val_score(rf,X=X_train,y=y_train,cv=CV,scoring='r2',error_score=np.nan,n_jobs=6)\n",
    "                  print(\"Random Forest Training done\")\n",
    "                  return (1-result.min())\n",
    "              \n",
    "            Space = {\n",
    "                      'n_estimators': 100, #scope.int(hp.quniform('n_estimators', 100,1200,50)),\n",
    "                      \"max_depth\": 20, # scope.int(hp.quniform('max_depth',2,30,1)),\n",
    "                      'max_features': hp.choice('max_features',['auto', 'sqrt','log2']),\n",
    "                      'min_samples_split': scope.int(hp.quniform('min_samples_split',2,15,1)),\n",
    "                      'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1,20,1)),\n",
    "                      'oob_score':False,\n",
    "                      'bootstrap':  hp.choice('bootstrap',[True, False])\n",
    "                  }                                                           \n",
    "      \n",
    "            bayes_trials = Trials()\n",
    "            try:\n",
    "                best = fmin(fn = objective, space = Space, algo = hyperopt.tpe.suggest,max_evals = MAX_EVALS, trials = bayes_trials)\n",
    "                print(\"HyperOP done for RF\")\n",
    "            except:\n",
    "                print(\"Hyperparameter tuning failed\")\n",
    "                best.clear()\n",
    "                best['oob_score']=False\n",
    "            else: \n",
    "                best['n_estimators']=100 #int(best['n_estimators'])\n",
    "                best['max_depth']= 20 #int(best['max_depth'])\n",
    "                best['min_samples_split']=int(best['min_samples_split'])\n",
    "                best['min_samples_leaf']=int(best['min_samples_leaf'])\n",
    "                fea=['auto', 'sqrt','log2']\n",
    "                best['max_features']=fea[best['max_features']]\n",
    "                best['oob_score']= False\n",
    "                boot=[True, False]\n",
    "                best['bootstrap']=boot[best['bootstrap']]\n",
    "                print(\"RF Hyperop done\")\n",
    "      \n",
    "            print(\"RF done\")\n",
    "            ########################################################################################################\n",
    "      \n",
    "\n",
    "            ##Random forest(2) Finding out accuracy on the test dataset\n",
    "            ########################################################################################################\n",
    "            et_dict = best.copy()\n",
    "            df.loc[ind,'Name']='Random Forest'\n",
    "            df['model'][ind]=RandomForestRegressor(**best)\n",
    "            df.loc[ind,'param']=str(best)\n",
    "            Start = time.time()\n",
    "            df.loc[ind,'model'].fit(X_train, y_train)\n",
    "            random_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "            End = time.time()\n",
    "            df.loc[ind,'accuracy']=r2_score(y_test, random_reg_prob1)*100\n",
    "            df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, random_reg_prob1))))\n",
    "            df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, random_reg_prob1))\n",
    "            df.loc[ind,'MSE'] = mean_squared_error(y_test, random_reg_prob1)\n",
    "            df.loc[ind,'MAE']=mean_absolute_error(y_test, random_reg_prob1)\n",
    "            #df.loc[ind,'AIC']=aic.aic(y_test, random_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'BIC']=bic.bic(y_test, random_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)       \n",
    "            print(\"RF Validation done\")\n",
    "            ind=ind+1\n",
    "      \n",
    "            ########################################################################################################\n",
    "    \n",
    "    \n",
    "            #ExtraTrees Regression\n",
    "            ######################################################################################################################### \n",
    "            df.loc[ind,'Name']='ExtraTrees Regressor'\n",
    "            df['model'][ind]=ExtraTreesRegressor(**et_dict)\n",
    "            df.loc[ind,'param']=str(best)\n",
    "            Start = time.time()\n",
    "            df.loc[ind,'model'].fit(X_train, y_train)\n",
    "            extra_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "            End = time.time()\n",
    "            df.loc[ind,'accuracy']=r2_score(y_test, extra_reg_prob1)*100\n",
    "            df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, extra_reg_prob1))))\n",
    "            df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, extra_reg_prob1))\n",
    "            df.loc[ind,'MSE'] = mean_squared_error(y_test, extra_reg_prob1)\n",
    "            df.loc[ind,'MAE']=mean_absolute_error(y_test, extra_reg_prob1)\n",
    "            #df.loc[ind,'AIC']=aic.aic(y_test, extra_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'BIC']=bic.bic(y_test, extra_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)      \n",
    "            print(\"ETextra_reg_prob1 Validation done\")\n",
    "            ind=ind+1\n",
    "      \n",
    "            ########################################################################################################\n",
    "\n",
    "\n",
    "            #Ridge Regression\n",
    "            ########################################################################################################\n",
    "            df.loc[ind,'Name']='Ridge Regression'\n",
    "            df.loc[ind,'model']=Ridge()\n",
    "            df.loc[ind,'param']=None\n",
    "            Start = time.time()\n",
    "            df.loc[ind,'model'].fit(X_train, y_train)\n",
    "            ridge_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "            End = time.time()\n",
    "            df.loc[ind,'accuracy']=r2_score(y_test, ridge_reg_prob1)*100\n",
    "            df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, ridge_reg_prob1))))\n",
    "            df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, ridge_reg_prob1))\n",
    "            df.loc[ind,'MSE'] = mean_squared_error(y_test, ridge_reg_prob1)\n",
    "            df.loc[ind,'MAE']=mean_absolute_error(y_test, ridge_reg_prob1)\n",
    "            #df.loc[ind,'AIC']=aic.aic(y_test, ridge_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'BIC']=bic.bic(y_test, ridge_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)     \n",
    "            print(\"ridge reg done\")\n",
    "            ind=ind+1\n",
    "\n",
    "            #Linear regression\n",
    "            ########################################################################################################\n",
    "            df.loc[ind,'Name']='Linear Regression'\n",
    "            df.loc[ind,'model']=LinearRegression()\n",
    "            df.loc[ind,'param']=None\n",
    "            Start = time.time()\n",
    "            df.loc[ind,'model'].fit(X_train, y_train)\n",
    "            logr_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "            End = time.time()\n",
    "            df.loc[ind,'accuracy']=r2_score(y_test, logr_reg_prob1)*100\n",
    "            df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, logr_reg_prob1))))\n",
    "            df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, logr_reg_prob1))\n",
    "            df.loc[ind,'MSE'] = mean_squared_error(y_test, logr_reg_prob1)\n",
    "            df.loc[ind,'MAE']=mean_absolute_error(y_test, logr_reg_prob1)\n",
    "            #df.loc[ind,'AIC']=aic.aic(y_test, logr_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'BIC']=bic.bic(y_test, logr_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)   \n",
    "      \n",
    "            print(\"linear reg done\")\n",
    "            ind=ind+1\n",
    "      \n",
    "            #Neural net\n",
    "            ########################################################################################################\n",
    "            best={'hidden_layer_sizes':(50,),'solver':'sgd','learning_rate':'adaptive','max_iter':1000,'early_stopping':True,'n_iter_no_change':30}\n",
    "            df.loc[ind,'Name']='Neural Net'\n",
    "            df.loc[ind,'model']=MLPRegressor(**best)\n",
    "            df.loc[ind,'param']=str(best)\n",
    "            Start = time.time()\n",
    "            df.loc[ind,'model'].fit(X_train, y_train)\n",
    "            mlpc_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "            End = time.time()\n",
    "            try:\n",
    "                df.loc[ind,'accuracy']=r2_score(y_test, mlpc_reg_prob1)*100\n",
    "            except:\n",
    "                print(\"Neural Net threw an error\")\n",
    "            else:\n",
    "                df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, mlpc_reg_prob1))))\n",
    "                df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, mlpc_reg_prob1))\n",
    "                df.loc[ind,'MSE'] = mean_squared_error(y_test, mlpc_reg_prob1)\n",
    "                df.loc[ind,'MAE']=mean_absolute_error(y_test, mlpc_reg_prob1)\n",
    "                #df.loc[ind,'AIC']=aic.aic(y_test, mlpc_reg_prob1,X_train.shape[1])\n",
    "                df.loc[ind,'BIC']=bic.bic(y_test, mlpc_reg_prob1,X_train.shape[1])\n",
    "                df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)     \n",
    "\n",
    "                print(\"neural net done\") \n",
    "                ind=ind+1\n",
    "        \n",
    "      \n",
    "            #Support Vector Machine\n",
    "            ########################################################################################################     \n",
    "            df.loc[ind,'Name']='Support Vector Machine'\n",
    "            df.loc[ind,'model']=svm.SVR(kernel='linear',max_iter=1000)\n",
    "            df.loc[ind,'param']=None\n",
    "            Start = time.time()\n",
    "            df.loc[ind,'model'].fit(X_train, y_train)\n",
    "            svc_reg_prob1 = df.loc[ind,'model'].predict(X_test)\n",
    "            End = time.time()\n",
    "            df.loc[ind,'accuracy']=r2_score(y_test, svc_reg_prob1)*100\n",
    "            df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, svc_reg_prob1))))\n",
    "            df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, svc_reg_prob1))\n",
    "            df.loc[ind,'MSE'] = mean_squared_error(y_test, svc_reg_prob1)\n",
    "            df.loc[ind,'MAE']=mean_absolute_error(y_test, svc_reg_prob1)\n",
    "            #df.loc[ind,'AIC']=aic.aic(y_test, svc_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'BIC']=bic.bic(y_test, svc_reg_prob1,X_train.shape[1])\n",
    "            df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)      \n",
    "      \n",
    "            print(\"SVC done\")\n",
    "            ind=ind+1 \n",
    "      \n",
    "      \n",
    "      \n",
    "      #Ensemble\n",
    "      ########################################################################################################\n",
    "      ##Ensemble(1) Finding all possible combination of above model and find out the best combination based on testing data accuracy\n",
    "      ########################################################################################################\n",
    "      arr1=np.empty((len(y_test),0))\n",
    "      for i in range(0,len(df)):\n",
    "          arr1=np.hstack((arr1,np.reshape(df.loc[i,'model'].predict(X_test),(len(y_test),1))))\n",
    "\n",
    "      min_rmse=100000\n",
    "      max_seq=0\n",
    "      for i in range(2,len(df)+1):\n",
    "          comb=list(combinations(enumerate(arr1.T), i))\n",
    "          for j in range(0,len(comb)):\n",
    "              m=np.empty((len(y_test),0))\n",
    "              for x in range(0,len(comb[j])):\n",
    "                  m=np.hstack((m,np.reshape(comb[j][x][1],(len(y_test),1))))  \n",
    "              arr=np.mean(m,axis=1)\n",
    "              rmse= sqrt(mean_squared_error(y_test, arr))\n",
    "              seq=np.array(comb[j])[:,0]\n",
    "              if rmse<min_rmse:\n",
    "                  min_rmse = rmse\n",
    "                  max_seq=seq\n",
    "      \n",
    "      print(\"this is what you are printing\",max_seq)\n",
    "      \n",
    "      ##############################################################################\n",
    "\n",
    "      ##Ensemble(2) List of the best combination from the above method\n",
    "      ########################################################################################################\n",
    "      name=''\n",
    "      df_en=pd.DataFrame(index = range(1000), columns=['Name','model'])\n",
    "      for i in range(0,len(max_seq)):\n",
    "        df_en.at[i,'Name']= df.at[max_seq[i],'Name']\n",
    "        val = df.at[max_seq[i],'model']\n",
    "        df_en['model'][i] = val\n",
    "        name=name+df['Name'][max_seq[i]]+'+'\n",
    "      \n",
    "    \n",
    "      df_en.dropna(axis=0,inplace=True)\n",
    "      ########################################################################################################\n",
    "      \n",
    "      \n",
    "      ##Ensemble(3) Making an esemble model of the best combination\n",
    "      ########################################################################################################\n",
    "      df.loc[ind,'Name']=('Ensemble '+name)[:-1]\n",
    "      df.loc[ind,'model']=VotingRegressor(df_en.values,n_jobs=-1)\n",
    "      df.loc[ind,'param']=\"Defualt\"\n",
    "      Start = time.time()\n",
    "      df.loc[ind,'model'].fit(X_train, y_train)\n",
    "      ensemble_pred = df.loc[ind,'model'].predict(X_test)\n",
    "      End = time.time()\n",
    "      df.loc[ind,'accuracy']=r2_score(y_test, ensemble_pred)*100\n",
    "      df.loc[ind,'Accuracy%']=\"{:.2%}\".format(Decimal(str(r2_score(y_test, ensemble_pred))))\n",
    "      df.loc[ind,'RMSE']=sqrt(mean_squared_error(y_test, ensemble_pred))\n",
    "      df.loc[ind,'MSE']=mean_squared_error(y_test, ensemble_pred)\n",
    "      df.loc[ind,'MAE']=mean_absolute_error(y_test, ensemble_pred)\n",
    "      #df.loc[ind,'AIC']=aic.aic(y_test, ensemble_pred,X_train.shape[1])\n",
    "      df.loc[ind,'BIC']=bic.bic(y_test, ensemble_pred,X_train.shape[1])\n",
    "      df.loc[ind,'Total time(mins)']= ((End-Start) / 60.0)      \n",
    "      ind=ind+1\n",
    "      \n",
    "      best_info=df.sort_values('RMSE',ignore_index=True,ascending=True).loc[0,:]\n",
    "      best_name=best_info['Name']\n",
    "      best_mod=best_info['model']\n",
    "      best_acc=best_info['accuracy']\n",
    "      best_param=best_info['param']\n",
    "    \n",
    "      joblib.dump(best_info,'best_info')\n",
    "      \n",
    "      return best_name,best_mod, best_acc, best_param,df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Visualization(X,Y,class_or_Reg):\n",
    "    import pydotplus\n",
    "    if class_or_Reg == 'Classification':\n",
    "        from sklearn import tree\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        import matplotlib.pyplot as plt\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        le = LabelEncoder()\n",
    "        Y = le.fit_transform(Y)#encoding the target variable\n",
    "        Yt=pd.DataFrame(Y)\n",
    "        clf = DecisionTreeClassifier(max_depth = 3, min_samples_split=2, min_samples_leaf=0.01, random_state = 1)\n",
    "        clf.fit(X, Y)\n",
    "        class_names=list(le.inverse_transform(sorted(Yt[Yt.columns[0]].unique())))\n",
    "        for i in range(len(class_names)):\n",
    "            class_names[i]=str(class_names[i])\n",
    "        print(\"value=[n1,n2,n3...] where n1,n2,n3 are the number of samples of the classes in the order     \\nvalue=\"+str(le.inverse_transform(sorted(Yt[Yt.columns[0]].unique()))))\n",
    "        tree.plot_tree(clf,\n",
    "                     feature_names =X.columns, #the list of all column names\n",
    "                     class_names=class_names, #list of the class names\n",
    "                     filled = True,\n",
    "                     impurity=False,\n",
    "                     rounded=True,\n",
    "                     fontsize=10);\n",
    "        dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                            feature_names=X.columns,  \n",
    "                            filled=True, impurity=False, rounded=True,  \n",
    "                            special_characters=True)\n",
    "        graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "        graph.write_png('CART.png')\n",
    "        graph.write_svg(\"CART.svg\")\n",
    "\n",
    "    else:\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        from sklearn import tree\n",
    "        import matplotlib.pyplot as plt\n",
    "        clf = DecisionTreeRegressor(max_depth = 3, min_samples_split=2, min_samples_leaf=0.01, random_state = 0)\n",
    "        clf.fit(X, Y)\n",
    "        tree.plot_tree(clf,\n",
    "                   feature_names =X.columns, \n",
    "                      filled = True,\n",
    "                     impurity=False,\n",
    "                     rounded=True,\n",
    "                     fontsize=10);\n",
    "        dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                             feature_names=X.columns,  \n",
    "                                filled=True, impurity=False, rounded=True,  \n",
    "                                special_characters=True)\n",
    "        graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "        graph.write_png('CART.png')\n",
    "        graph.write_svg(\"CART.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quicker/Slower Results for setting max evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_slow():\n",
    "    inp = input('Do you want quick results or slower results? If quick enter y : ').lower()\n",
    "    return True if inp == 'y' else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUserInput(df):\n",
    "    if isinstance(df,pd.DataFrame):\n",
    "        print('\\nDataFrame Succesfully imported\\n')\n",
    "            \n",
    "        print(df.columns)\n",
    "\n",
    "        # Get Target from user\n",
    "        target = getTarget(df.columns)\n",
    "\n",
    "        if not target:\n",
    "            # Quit the whole process\n",
    "            print('\\nQuitting Process\\n')\n",
    "            return None\n",
    "        else: \n",
    "            # Get Key Column\n",
    "            key = getKey(df.columns)\n",
    "            if not key:\n",
    "                key = findKey(df.columns[0])\n",
    "            if key:\n",
    "                df.drop(key,axis=1,inplace=True)           \n",
    "                \n",
    "            # Remove User Specified ID Columns\n",
    "            df = removeUserSpecifiedIDs(df,True)\n",
    "                \n",
    "            # Remove Successive Targets\n",
    "            df = removeUserSpecifiedIDs(df)\n",
    "            \n",
    "            # Quick/Slow results for max evals\n",
    "            quick = quick_slow()\n",
    "            if quick:print('DEFAULT MODELS WILL BE RUNNING')\n",
    "            else:print('HYPERPARAMETER OPTIMISATION WILL BE RUN ON MODELS')\n",
    "        \n",
    "        info = {'target':target,'key':key,'cols':df.drop([target],axis=1).columns.to_list(),'q_s':quick}\n",
    "        \n",
    "        return info\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Classes with 0.05% Occurence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeLowClass(targetColumn):\n",
    "    vc = targetColumn.value_counts(normalize=True)<0.005\n",
    "    classes = vc[vc==True].index\n",
    "    if len(classes)!=0:\n",
    "        print('Classes {} will be removed from the data, as they have less than 0.5% occurence'.format(classes))\n",
    "        print('and create class imbalance which might affect model performances!')\n",
    "        return targetColumn.drop(classes).index\n",
    "    else:\n",
    "        print('No Class was found less than 0.5% occurence!')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureSelectionPlot(feat_df):\n",
    "    import seaborn as sns\n",
    "    f = 20\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.title('Feature Importance Plot',fontsize=f)\n",
    "    sns.barplot(x='scores2',y='col_name',data=feat_df,palette=\"Blues_d\")\n",
    "    plt.xlabel('Importance',fontsize=f)\n",
    "    plt.ylabel('Feature',fontsize=f)\n",
    "    plt.xticks(fontsize=12,rotation=90)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEEQpoGCyf33"
   },
   "source": [
    "**INIT DATA PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsxVaAO571Xn"
   },
   "outputs": [],
   "source": [
    "def INIT(df,info):\n",
    "    target = info['target']\n",
    "    key = info['key']\n",
    "    cols = info['cols']\n",
    "    cols.append(target)\n",
    "    if key:\n",
    "        cols.append(key)\n",
    "    df = df[cols]\n",
    "    # Print columns with missing data in the descending order\n",
    "    MISSING = pd.DataFrame(((df.isnull().sum().sort_values(ascending=False)*100/len(df)).round(2)),columns=['Missing in %'])[:10]\n",
    "    print(MISSING)\n",
    "    \n",
    "    ############ TARGET NUMERIC ENGINEERING ###########\n",
    "    print('\\n ### Entering Numeric Engineering of Target### \\n')\n",
    "    df = numeric_engineering(df)\n",
    "    ############ TARGET NUMERIC ENGINEERING ###########\n",
    "\n",
    "    # Find Classification or Regression\n",
    "    class_or_Reg = None #INIT\n",
    "    class_or_Reg = targetAnalysis(df[target])\n",
    "    if not class_or_Reg:\n",
    "        print('\\nExecution stops as We cant deal with such a target')\n",
    "        return None,None\n",
    "    \n",
    "    if class_or_Reg == 'Classification':\n",
    "        # Remove Classes with less than 0.05% occurence\n",
    "        if df[target].nunique() >2:  #removalof low class not done if binary classification\n",
    "            lowClassRows = removeLowClass(df[target])\n",
    "            if lowClassRows:\n",
    "                if len(lowClassRows)!=0:\n",
    "                    df.drop(lowClassRows,inplace=True)\n",
    "\n",
    "                if df[target].nunique() == 1:\n",
    "                    print('For Classification at least 2 classes are expected! Hence Execution Stops!')\n",
    "                    return None,None\n",
    "    \n",
    "    print('{} column needs {}'.format(target,class_or_Reg))\n",
    "    ues = time.time()\n",
    "#     if key:userInteractVisualization(df.drop(key,axis=1),target)\n",
    "#     else:userInteractVisualization(df,target)\n",
    "    uee = time.time()\n",
    "    print('Bi/Uni Variate Plotter time taken : {}'.format(uee-ues))\n",
    "\n",
    "    # Remove all rows with Target Column Empty\n",
    "    beforeIndex = df.index\n",
    "    df.dropna(subset=[target],inplace=True)\n",
    "    afterIndex = df.index\n",
    "    rowsRemoved = list(set(beforeIndex)-set(afterIndex))\n",
    "    print('\\n {} rows were removed since target had these missing'.format(len(rowsRemoved)))\n",
    "    del beforeIndex,afterIndex\n",
    "\n",
    "    ############# TRAIN VALIDATION SPLIT ###########\n",
    "    if class_or_Reg == 'Classification':                        \n",
    "        LE = LabelEncoder()                        \n",
    "        df[target] = LE.fit_transform(df[target])\n",
    "        try:                      \n",
    "            train,validation = train_test_split(df,test_size=0.2,random_state=1,stratify=df[target])    \n",
    "        except:\n",
    "            train,validation = train_test_split(df,test_size=0.2,random_state=1)               \n",
    "    else:\n",
    "        LE = None\n",
    "        df[target].clip(lower=df[target].quantile(0.1),upper=df[target].quantile(0.9),inplace=True) \n",
    "        try:                       \n",
    "            train,validation = train_test_split(df,test_size=0.2,random_state=1,stratify=df[target])\n",
    "        except:\n",
    "            train,validation = train_test_split(df,test_size=0.2,random_state=1)\n",
    "    ############# TRAIN VALIDATION SPLIT ###########\n",
    "\n",
    "    X = train.drop(target,axis=1)\n",
    "    y = train[target]\n",
    "    if key:\n",
    "        X.drop(key,axis=1,inplace=True)\n",
    "    del train\n",
    "    del df\n",
    "\n",
    "    # Remove columns and rows with more than 50% missing values\n",
    "    print('\\nRemoving Rows and Columns with more than 50% missing\\n')\n",
    "    X,y = DatasetSelection(X,y)\n",
    "    \n",
    "    ######## DATE ENGINEERING #######\n",
    "    print('\\n#### DATE ENGINEERING RUNNING WAIT ####')\n",
    "    date_cols = getDateColumns(X.sample(1500) if len(X) > 1500 else X)\n",
    "    print('Date Columns found are {}'.format(date_cols))\n",
    "    if date_cols:         \n",
    "        print('Respective columns will undergo date engineering and will be imputed in the function itself')\n",
    "        print('\\n#### DATE ENGINEERING RUNNING WAIT ####')\n",
    "        try:\n",
    "            DATE_DF = date_engineering(X[date_cols])\n",
    "            print(DATE_DF.shape)\n",
    "            DATE_DF.index = X.index\n",
    "            X.drop(date_cols,axis=1,inplace=True)\n",
    "            before = len(DATE_DF.columns)\n",
    "            DATE_DF.dropna(axis=1,thresh=len(DATE_DF)*0.4,inplace=True)\n",
    "            after = len(DATE_DF.columns)\n",
    "            print('{} columns removed due to highly missing'.format(before-after))\n",
    "            del before,after\n",
    "            DATE_DF = DATE_DF.fillna(DATE_DF.mean()) \n",
    "        except:\n",
    "            print('#### DATE ENGINEERING HAD ERRORS ####')\n",
    "            X.drop(date_cols,axis=1,inplace=True)\n",
    "            DATE_DF = pd.DataFrame(None)\n",
    "    else:\n",
    "        DATE_DF = pd.DataFrame(None)\n",
    "    print(' #### DONE ####') \n",
    "    ######## DATE ENGINEERING #######\n",
    "    \n",
    "    ######## COLUMN SEGREGATION ########\n",
    "    print('\\n ### Entering Segregation Zone ### \\n')\n",
    "    # Feature Reduction and Segregation of discrete columns\n",
    "\n",
    "    num_df, disc_df, useless_cols = Segregation(X)\n",
    "    disc_df = disc_df.astype('category')\n",
    "    disc_cat = {}\n",
    "    for column in disc_df:\n",
    "        disc_cat[column] = disc_df[column].cat.categories\n",
    "\n",
    "    ############# OUTLIER REMOVAL ###########\n",
    "    print('\\n#### OUTLIER WINSORIZING ####')\n",
    "    num_df.clip(lower=num_df.quantile(0.1),upper=num_df.quantile(0.9),inplace=True,axis=1)\n",
    "    print(' #### DONE ####')\n",
    "    ############# OUTLIER REMOVAL ###########\n",
    "    \n",
    "    ######## TEXT ENGINEERING #######\n",
    "    start1 = time.time()\n",
    "    start = time.time()\n",
    "    some_list, remove_list = findReviewColumns(X[useless_cols])  #list1 contains list of usable comment columns, list2 contains list of unusable comment columns\n",
    "    end = time.time()\n",
    "    print(\"Extracting Review Columns time\",end-start)\n",
    "    if (some_list is None):\n",
    "      TEXT_DF = pd.DataFrame(None)\n",
    "      lda_models = pd.DataFrame(None)\n",
    "      print(\"No review/comment columns found\")\n",
    "    else:\n",
    "        try:\n",
    "            print('Respective columns will undergo text engineering and will be imputed in the function itself')\n",
    "            print('\\n#### TEXT ENGINEERING RUNNING WAIT ####')  \n",
    "            print(\"The review/comment columns found are\", some_list)\n",
    "            start = time.time()\n",
    "            sentiment_frame = sentiment_analysis(X[some_list])\n",
    "            sentiment_frame.fillna(value=0.0,inplace=True)\n",
    "            print(sentiment_frame)\n",
    "            #TEXT_DF = pd.concat([df, sentiment_frame], axis=1, sort=False)\n",
    "            TEXT_DF = sentiment_frame.copy()\n",
    "            TEXT_DF.reset_index(drop=True,inplace=True)\n",
    "            end = time.time()\n",
    "            print(\"Sentiment time\",end-start)\n",
    "            start = time.time()\n",
    "            new_frame = X[some_list].copy()\n",
    "            new_frame.fillna(value=\"None\",inplace=True)\n",
    "            lda_models = pd.DataFrame(index= range(5),columns=['Model'])\n",
    "            ind = 0\n",
    "            \n",
    "            for col in new_frame.columns:\n",
    "                topic_frame, lda_model = topicExtraction(new_frame[[col]])\n",
    "                topic_frame.rename(columns={0:str(col)+\"_Topic\"},inplace=True)\n",
    "                print(topic_frame)\n",
    "                topic_frame.reset_index(drop=True, inplace=True)\n",
    "                TEXT_DF = pd.concat([TEXT_DF, topic_frame], axis=1, sort=False)\n",
    "                lda_models['Model'][ind] = lda_model\n",
    "                ind = ind+1\n",
    "            end = time.time()\n",
    "            print(\"Topic time\", end-start)\n",
    "            X.drop(some_list,axis=1,inplace=True)\n",
    "            X.drop(remove_list,axis=1, inplace=True)\n",
    "            lda_models.dropna(axis=0,inplace=True)\n",
    "        except:\n",
    "            print('#### TEXT ENGINEERING HAD ERRORS ####')\n",
    "            X.drop(some_list,inplace=True)\n",
    "            if(remove_list):\n",
    "                X.drop(remove_list,axis=1,inplace=True)\n",
    "            TEXT_DF = pd.DataFrame(None)\n",
    "            lda_models = pd.DataFrame(None)\n",
    "    \n",
    "    end2= time.time()\n",
    "    \n",
    "    print(\"total text analytics time taken =\", end2-start1) \n",
    "    print(\"Text Engineering Result\", TEXT_DF)\n",
    "    \n",
    "    #TEXT_DF holds the columns obtained from Text Engineering and\n",
    "    #X contains the columns after Text imputation\n",
    "    \n",
    "    ########################### TEXT ENGINEERING #############################\n",
    "\n",
    "    ############# PEARSON CORRELATION ############\n",
    "    print('\\n #### PEARSON CORRELATION ####')\n",
    "    corr = num_df.corr(method='pearson')                                              \n",
    "    corr = corr[(corr >= 0.85)]\n",
    "    for column in corr.columns:                                                   \n",
    "        corr.loc[column][column] = np.nan    \n",
    "    corr.dropna(axis=1,how='all',inplace=True)                                    \n",
    "    corr.dropna(axis=0,how='all',inplace=True)\n",
    "    removed_cols = []\n",
    "    if corr.shape!=(0,0):                                                                                                                    \n",
    "\n",
    "        while corr.shape != (0,0):                                                  \n",
    "            corr_dict = {}                                                            \n",
    "            for column in corr.columns:                                               \n",
    "                corr_dict[corr[column].max()] = column\n",
    "            try:\n",
    "                val = max(corr_dict)\n",
    "                corr.drop(corr_dict[val],inplace=True)\n",
    "                corr.drop(corr_dict[val],axis=1,inplace=True)\n",
    "                corr.dropna(axis=1,how='all',inplace=True)\n",
    "                corr.dropna(axis=0,how='all',inplace=True)\n",
    "                removed_cols.append(corr_dict[val])\n",
    "                del corr_dict[val]\n",
    "            except ValueError:                                                        \n",
    "                break\n",
    "    num_df.drop(removed_cols,axis=1,inplace=True)\n",
    "    print('\\n{} columns removed which were highly correlated'.format(len(removed_cols)))\n",
    "    print('The columns removed are {}'.format(removed_cols))\n",
    "    print(' #### DONE ####') \n",
    "    ############# PEARSON CORRELATION ############\n",
    "  \n",
    "    num_df.reset_index(drop=True, inplace=True)\n",
    "    disc_df.reset_index(drop=True, inplace=True)\n",
    "    DATE_DF.reset_index(drop=True, inplace=True)\n",
    "    TEXT_DF.reset_index(drop=True, inplace=True)\n",
    "    concat_list = [num_df,disc_df,DATE_DF,TEXT_DF]\n",
    "    X = pd.concat(concat_list,axis=1)\n",
    "    \n",
    "    print('\\n #### TRANSFORMATIONS ####')\n",
    "    TE = TargetEncoder(cols=disc_df.columns)\n",
    "    print('\\n #### TARGET ENCODING ####')\n",
    "    te_start = time.time()\n",
    "    X = TE.fit_transform(X,y)\n",
    "    te_end = time.time()\n",
    "    print('Target Encoding Time taken : {}'.format(te_end-te_start))\n",
    "    print('\\n #### FEATURE SELECTION ####')\n",
    "    fe_s = time.time()\n",
    "    rem,feat_df = FeatureSelection(X,y,class_or_Reg)\n",
    "    fe_e = time.time()\n",
    "    print('Feature Selection Time taken : {}'.format(fe_e-fe_s))\n",
    "    X.drop(rem,axis=1,inplace=True)\n",
    "    fe_s = time.time()\n",
    "    try:\n",
    "        featureSelectionPlot(feat_df[:15])\n",
    "    except:\n",
    "        print('\\nFEATURE SELECTION PLOT DID NOT RUN SUCCESSFULLY!')\n",
    "    fe_e = time.time()\n",
    "    print('Feature Selection Plot Time taken : {}'.format(fe_e-fe_s))\n",
    "    print('\\n #### DECISION TREE VISUALIZATION ####')\n",
    "    try:\n",
    "        Visualization(X,y,class_or_Reg)\n",
    "    except:\n",
    "        print('#### VISUALIZATION DID NOT RUN AND HAD ERRORS ####')\n",
    "    \n",
    "    TrainingColumns = X.columns\n",
    "\n",
    "    print('\\n #### Printing Sample Equation of the DATA ####')\n",
    "    try:\n",
    "        SampleEquation(X,y,class_or_Reg)\n",
    "    except:\n",
    "        print('SAMPLE EQUATION HAD AN ERROR!!!')\n",
    "    print(' #### DONE ####')\n",
    "\n",
    "    print('\\n #### NORMALIZATION ####')\n",
    "    MM = MinMaxScaler()\n",
    "    GG = MinMaxScaler()\n",
    "    X = MM.fit_transform(X)\n",
    "    print(' #### DONE ####')\n",
    "    print('\\n #### POWER TRANSFORMATIONS ####')\n",
    "    PT = PowerTransformer(standardize=True)\n",
    "    X = pd.DataFrame(PT.fit_transform(X))\n",
    "    X.columns = TrainingColumns\n",
    "    X = pd.DataFrame(GG.fit_transform(X))\n",
    "    X.columns = TrainingColumns\n",
    "    print(' #### DONE ####')\n",
    "    \n",
    "\n",
    "    print('\\n #### SAVING MODEL INFORMATION ####')\n",
    "    init_info = {'NumericColumns':num_df.columns,'NumericMean':num_df.mean().to_dict(),'DiscreteColumns':disc_df.columns,\n",
    "                'DateColumns':date_cols,'DateFinalColumns':DATE_DF.columns,'DateMean':DATE_DF.mean().to_dict(),\n",
    "                'TargetEncoder':TE,'MinMaxScaler':MM,'PowerTransformer':PT,'TargetLabelEncoder':LE,'Target':target,\n",
    "                 'TrainingColumns':TrainingColumns,\n",
    "                'ML':class_or_Reg,'KEY':key,'X_train':X,'y_train':y,'disc_cat':disc_cat,'q_s':info['q_s'],'some_list':some_list,'remove_list':remove_list,'lda_models':lda_models}\n",
    "    print(' #### DONE ####')\n",
    "    return init_info,validation                                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EKgi0b13yoO_"
   },
   "source": [
    "**VALIDATION TRAINING AND SCORING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TOseeYB6dA1x"
   },
   "outputs": [],
   "source": [
    "def validate(df,init_info):\n",
    "    print('\\n\\t #### VALIDATION AND SCORING ZONE ####')\n",
    "    \n",
    "    X_train = init_info['X_train']\n",
    "    y_train = init_info['y_train']\n",
    "    \n",
    "    if init_info['ML'] == 'Classification':  \n",
    "        priorList = y_train.value_counts(normalize=True).values\n",
    "    else:\n",
    "        priorList = None\n",
    "\n",
    "    X_test = df.drop(init_info['Target'],axis=1)\n",
    "    y_test = df[init_info['Target']]\n",
    "\n",
    "    if init_info['KEY']:\n",
    "        k_test = df[init_info['KEY']]\n",
    "        k_test.index = X_test.index\n",
    "    else:\n",
    "        k_test = X_test.index\n",
    "        k_test.name = 'S.No'\n",
    "    \n",
    "    date_cols = init_info['DateColumns']\n",
    "    if date_cols:\n",
    "        DATE_DF = date_engineering(X_test[date_cols])\n",
    "        DATE_DF = DATE_DF[init_info['DateFinalColumns']]\n",
    "        DATE_DF.fillna(init_info['DateMean'],inplace=True)\n",
    "    else:\n",
    "        DATE_DF = pd.DataFrame()\n",
    "    \n",
    "    if len(init_info['NumericColumns'])!=0:\n",
    "        num_df = X_test[init_info['NumericColumns']]\n",
    "        num_df = num_df.swifter.apply(lambda x : pd.to_numeric(x,errors='coerce'))\n",
    "        num_df.fillna(init_info['NumericMean'],inplace=True)\n",
    "    else:\n",
    "        num_df = pd.DataFrame()\n",
    "        \n",
    "    if len(init_info['DiscreteColumns'])!=0:\n",
    "        disc_df = X_test[init_info['DiscreteColumns']]\n",
    "        disc_cat = init_info['disc_cat']\n",
    "        for col in disc_df.columns:\n",
    "            disc_df[col] = disc_df[col].apply(lambda x: x if x in disc_cat[col] else 'others')\n",
    "        disc_df.fillna('missing',inplace=True)\n",
    "    else:\n",
    "        disc_df = pd.DataFrame()\n",
    "        \n",
    "    if init_info['remove_list'] is not None:\n",
    "        X_test.drop(columns=init_info['remove_list'],axis=1,inplace=True)\n",
    "    \n",
    "    some_list = init_info['some_list']\n",
    "    lda_models = init_info['lda_models']\n",
    "    \n",
    "    if some_list:\n",
    "        print(\"The review/comment columns found are\", some_list)\n",
    "        start = time.time()\n",
    "        sentiment_frame = sentiment_analysis(X_test[some_list])\n",
    "        sentiment_frame.fillna(value=0.0,inplace=True)\n",
    "        print(sentiment_frame)\n",
    "        TEXT_DF = sentiment_frame.copy()\n",
    "        TEXT_DF.reset_index(drop=True,inplace=True)\n",
    "        end = time.time()\n",
    "        print(\"Sentiment time\",end-start)\n",
    "        start = time.time()\n",
    "        new_frame = X_test[some_list].copy()\n",
    "        new_frame.fillna(value=\"None\",inplace=True)\n",
    "        ind = 0\n",
    "        for col in new_frame.columns:\n",
    "            topic_frame, _ = topicExtraction(new_frame[[col]],True,lda_models['Model'][ind])\n",
    "            topic_frame.rename(columns={0:str(col)+\"_Topic\"},inplace=True)\n",
    "            print(topic_frame)\n",
    "            topic_frame.reset_index(drop=True, inplace=True)\n",
    "            TEXT_DF = pd.concat([TEXT_DF, topic_frame], axis=1, sort=False)\n",
    "            ind = ind+1\n",
    "        X_test.drop(some_list,axis=1,inplace=True)\n",
    "    else:\n",
    "        TEXT_DF = pd.DataFrame()\n",
    "        \n",
    "    \n",
    "    print('\\n #### TRANSFORMATION AND PREDICTION ####')\n",
    "    num_df.reset_index(drop=True, inplace=True)\n",
    "    disc_df.reset_index(drop=True, inplace=True)\n",
    "    DATE_DF.reset_index(drop=True, inplace=True)\n",
    "    TEXT_DF.reset_index(drop=True, inplace=True)\n",
    "    X_test = pd.concat([num_df,disc_df,DATE_DF,TEXT_DF],axis=1)\n",
    "    X_test = init_info['TargetEncoder'].transform(X_test)\n",
    "    X_test = X_test[init_info['TrainingColumns']]\n",
    "    X_test = X_test.fillna(X_test.mode())\n",
    "    mm = init_info['MinMaxScaler']\n",
    "    GG = MinMaxScaler()\n",
    "    X_test.clip(mm.data_min_,mm.data_max_,inplace=True,axis=1) #Clip the data with training min and max, important\n",
    "    X_test = mm.transform(X_test)\n",
    "    X_test = pd.DataFrame(init_info['PowerTransformer'].transform(X_test),columns=init_info['TrainingColumns'])\n",
    "    X_test = pd.DataFrame(GG.fit_transform(X_test),columns=init_info['TrainingColumns'])\n",
    "    \n",
    "    \n",
    "    print('\\n #### PRINTING THE LIST OF COLUMNS AND ITS TYPES THAT ENTER THE MODEL TRAINING ####')\n",
    "    print('#### PRINTING X_test ####')\n",
    "    print(X_test.columns)\n",
    "    print(X_test.dtypes)\n",
    "    print('\\n')\n",
    "    print(X_test.head(20))\n",
    "    print('\\n\\n')\n",
    "    print('#### PRINTING X_train ####')\n",
    "    print(X_train.columns)\n",
    "    print(X_train.dtypes)\n",
    "    print('\\n')\n",
    "    print(X_train.head(20))\n",
    "    print('\\n\\n')\n",
    "    print(X_test.columns)\n",
    "    print(X_test.dtypes)\n",
    "    start = time.time()\n",
    "    \n",
    "    X_train.fillna(0,inplace=True)\n",
    "    X_test.fillna(0,inplace=True)\n",
    "    y_train.fillna(0,inplace=True)\n",
    "    y_test.fillna(0,inplace=True)\n",
    "    ############# MODEL TRAINING #############\n",
    "    mod,model_info = model_training(X_train,y_train,X_test,y_test,init_info['ML'],priorList,init_info['q_s'])\n",
    "    ############# MODEL TRAINING #############\n",
    "    end = time.time()\n",
    "    print('\\nTotal Model Training Time taken : {}'.format(end-start))\n",
    "    init_info['model']=mod\n",
    "    init_info['model_info'] = model_info\n",
    "    del init_info['X_train'],init_info['y_train']                  # This removes the data from dict to avoid storage\n",
    "    joblib.dump(init_info,'ALL INFORMATION')\n",
    "    print('MODEL SAVED')\n",
    "    ############# PREDICTION/SCORING #############\n",
    "\n",
    "#     xg = XGBClassifier()\n",
    "#     xg = XGBRegressor()\n",
    "#     xg.fit(X_train,y_train)\n",
    "#     y_pred = xg.predict(X_test)  \n",
    "#     mod = joblib.load('model')\n",
    "    y_pred = mod.predict(X_test)  \n",
    "    \n",
    "    regplotdf=pd.DataFrame()\n",
    "    regplotdf['y_test']=y_test\n",
    "    regplotdf['y_pred']=y_pred\n",
    "    \n",
    "    if init_info['ML'] == 'Classification':\n",
    "#         y_probas = xg.predict_proba(X_test)\n",
    "        y_probas = mod.predict_proba(X_test)\n",
    "        y_pred = init_info['TargetLabelEncoder'].inverse_transform(y_pred)\n",
    "        y_test = pd.Series(init_info['TargetLabelEncoder'].inverse_transform(y_test))\n",
    "        y_probs_cols = ['Class ' + str(x) +' Probabilities' for x in y_test.unique()]\n",
    "        y_probas = pd.DataFrame(y_probas,columns=y_probs_cols)        \n",
    "        \n",
    "        from sklearn.metrics import classification_report\n",
    "        print(classification_report(y_test,y_pred))\n",
    "\n",
    "        skplt.metrics.plot_confusion_matrix(y_test, y_pred)\n",
    "        if len(priorList) ==2:\n",
    "            skplt.metrics.plot_lift_curve(y_test, y_probas)\n",
    "            skplt.metrics.plot_cumulative_gain(y_test, y_probas)\n",
    "        skplt.metrics.plot_roc(y_test, y_probas)\n",
    "        \n",
    "    else:\n",
    "        import seaborn as sns\n",
    "        import math\n",
    "        \n",
    "        #residual plot\n",
    "        fig1 = sns.residplot('y_test','y_pred',regplotdf)\n",
    "        plt.xlabel(\"Predicted Values\")\n",
    "        plt.ylabel(\"Residuals\")\n",
    "        plt.title(\"Residual Plot\") \n",
    "        plt.show(fig1)\n",
    "\n",
    "        #lm plot\n",
    "        fig2 = sns.lmplot('y_pred','y_test',regplotdf,fit_reg =True)\n",
    "        plt.xlabel(\"Predicted Values\")\n",
    "        plt.ylabel(\"Actual Values\")\n",
    "        plt.title(\"Predicted vs Actual\") \n",
    "        plt.show(fig2)\n",
    "        \n",
    "        # decile plot function\n",
    "        def decileplot(regplotdf):\n",
    "            div=math.floor(len(regplotdf)/10)\n",
    "            sorted_df= pd.DataFrame(regplotdf.sort_values('y_test',ascending=False))\n",
    "            sorted_df['decile']=0\n",
    "            for i in range(1,11):\n",
    "                sorted_df.iloc[div*(i-1):div*i,2]= i\n",
    "            sorted_df = sorted_df[sorted_df.decile != 0]\n",
    "            df_mean=pd.DataFrame()\n",
    "            df_mean[['Decile','Actualvalue_mean','Predictedvalue_mean']]=sorted_df.groupby('decile', as_index=False)[['y_test','y_pred']].mean()\n",
    "            fig, ax1 = plt.subplots(figsize=(10, 7))\n",
    "            plt.xticks(df_mean['Decile'])\n",
    "            tidy = pd.melt(df_mean, id_vars='Decile', value_vars= ['Actualvalue_mean','Predictedvalue_mean'],value_name='Mean values per decile')\n",
    "            sns.lineplot(x='Decile', y='Mean values per decile', hue='variable', data=tidy, ax=ax1)\n",
    "            print(df_mean)\n",
    "\n",
    "        # decile plot   \n",
    "        decileplot(regplotdf)\n",
    "        \n",
    "#         return None\n",
    "#         y_pred = xg.predict(X_test)\n",
    "#         y_pred = mod.predict(X_test)\n",
    "\n",
    "        y_probas = pd.Series()\n",
    "        fig3 = plt.figure()\n",
    "        plt.plot(y_pred, figure =fig3)\n",
    "        plt.plot(np.ones(len(y_pred))*y_pred.mean(), figure=fig3)\n",
    "        plt.show()\n",
    "        \n",
    "    ############ PREDICTION/SCORING #############\n",
    "\n",
    "    preview_length = 100 if len(X_test)>100 else len(X_test)\n",
    "    preview = pd.DataFrame({k_test.name:k_test.tolist(),\n",
    "                            'Actual Values':y_test.tolist(),\n",
    "                            'Predicted Values':y_pred.tolist()})\n",
    "    if init_info['ML'] == 'Classification':\n",
    "        preview = pd.concat([preview,y_probas],axis=1)\n",
    "    preview = preview[:preview_length]\n",
    "    preview.to_csv('preview.csv',sep=',',index=False)\n",
    "    print('\\nFile Saved as preview.csv')\n",
    "    print('\\nCode executed Successfully')\n",
    "    print('\\n############# END ###########')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FZ_AJGpyW-qs"
   },
   "source": [
    "## Input for Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aE8A1__dW-qs"
   },
   "outputs": [],
   "source": [
    "def data_model_select(X_train,y_train):\n",
    "  if len(X_train) <= 10000:\n",
    "    input_X_train = X_train\n",
    "    input_y_train = y_train\n",
    "  elif len(X_train) > 10000 & len(X_train) <= 100000:\n",
    "    input_X_train = X_train.sample(frac=0.8, random_state=1)\n",
    "    input_y_train = y_train.sample(frac=0.8, random_state=1)\n",
    "  elif len(X_train) > 100000 & len(X_train) < 1000000:\n",
    "    input_X_train = X_train.sample(frac=0.7, random_state=1)\n",
    "    input_y_train = y_train.sample(frac=0.7, random_state=1)\n",
    "  else:\n",
    "    input_X_train = X_train.sample(frac=0.5, random_state=1)\n",
    "    input_y_train = y_train.sample(frac=0.5, random_state=1)\n",
    "  return input_X_train,input_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o3qCHkrmW-qt"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zSfLuCDUW-qt"
   },
   "outputs": [],
   "source": [
    "def model_training(X_train,y_train,X_test,y_test,class_or_Reg,priorList,q_s):\n",
    "  # Selecting best model\n",
    "  if class_or_Reg == 'Classification':\n",
    "    Classification=classification()\n",
    "    input_X_train,input_y_train=data_model_select(X_train,y_train)\n",
    "    name,mod,acc,par,model_info = Classification.best_model_class(input_X_train, X_test, input_y_train.values, y_test.values,priorList,q_s)\n",
    "  else:#Regression\n",
    "    regression=Regression()\n",
    "    input_X_train,input_y_train=data_model_select(X_train,y_train)\n",
    "    name,mod,acc,par,model_info = regression.best_model_reg(input_X_train, X_test, input_y_train, y_test,q_s)\n",
    "  print('Accuracy :',acc)\n",
    "  # Saving the model\n",
    "  filename = 'finalized_model.sav' \n",
    "  joblib.dump(mod, filename)\n",
    "  return mod,model_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yD_olQmjnuvW"
   },
   "source": [
    "**Input Data File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "w6U-K-EW3De2",
    "outputId": "5b447047-9c6c-45e6-c19e-fee744844e89",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quitting Process\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############## CHANGE THE FILE NAME HERE ##############\n",
    "path = input('Enter the path here : ')\n",
    "error=False\n",
    "if path:\n",
    "    df = importFile(path,nrows=20)\n",
    "    info = getUserInput(df)\n",
    "    if not info:\n",
    "        error = True\n",
    "else:\n",
    "    df = None\n",
    "    print('\\nQuitting Process\\n')\n",
    "    error = True\n",
    "############## CHANGE THE FILE NAME HERE ##############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lC9-3eWpnxzZ"
   },
   "source": [
    "**RUN THIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c039df7ed11040129e03a83dbe1e138d",
      "c48d6b48a10e44ecb77d4bc524f8f9d5",
      "4c9b0446b2c3406690e048208bc68848",
      "4d23402341ba43b4bb67151aeb0bf74c",
      "aeaad849062f40e1934c6314a24308c3",
      "72ffbe6cb217412e9b3e4fcba38c771b",
      "6cdd8a146e824ad2873f30a3ee0186f7",
      "f3c4fc04b06d47b2b699b3f6e31aa8fb",
      "7c37357adf69400da78a0a350d754e44",
      "79c3dbeda6844b80850c3c0ccee95347",
      "7a369587e849478d98a9e9d65d25df9e",
      "5d01338bb9564ca3ab13cf8bab018480",
      "24fc9010901740679c49571afdb6af08",
      "1b9379302ba643c292e33a1d16a2e872",
      "364c3c26e6b449dd937188e102d8187a",
      "3f12adb7bd824cbaa58acb0ab50a44b1",
      "8586b34d1b4c4cb984a0204b1d9bf300",
      "f7f7e85b58054caea83f86297c6e24a4",
      "d412dd173e9e4818a13bee6e87f6fe31",
      "dd7591443b2544fc942afc5501fbd756",
      "571bbfcf6c434c018a0df5e288116fc1",
      "80bd764f22064ae4aced600f5e229e57",
      "d52d175248b94390a28f2f443f34e77c",
      "61f3492c000447c59bfcd2c4cd7a892e",
      "3d389453f1854c9ca588f508045fea82",
      "f74f0b3c5896413cbd6e50828658cba3",
      "2d7d099028864b66bf6457676d0cfba4",
      "6df49d042cb845988a38c369725ccb4d",
      "a313c13925be48949198b0e59006e842",
      "9fad02bdb1e748a69bd71faf4e417d7d",
      "a0c454b134d9457baf8573dfdef35720",
      "ab7b1ac3f5d249b1a925768b117b1843"
     ]
    },
    "colab_type": "code",
    "id": "tCbZph2Zx3OB",
    "outputId": "eae7f8c9-38a3-4e8e-f101-8166f245c28e",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### RUNNING WAIT ####\n",
      "Extension NOT FOUND!\n",
      "\n",
      " TOTAL TRAINING DATA CLEANING AND PLOTS : 0.019687891006469727\n",
      "\n",
      "\t #### CODE DID NOT RUN COMPLETELY ####\n",
      "\n",
      "#### TOTAL TIME TAKEN : 0.020446062088012695 ####\n"
     ]
    }
   ],
   "source": [
    "te = time.time()\n",
    "try:\n",
    "    if info:\n",
    "        ################## TRAINING INIT ##################\n",
    "        df = importFile(path,nrows=None)\n",
    "        tts = time.time()\n",
    "        if isinstance(df,pd.DataFrame):\n",
    "            init_info,validation = INIT(df,info)\n",
    "        else:\n",
    "            init_info,validation = None,None\n",
    "        tte = time.time()\n",
    "        print('\\n TOTAL TRAINING DATA CLEANING AND PLOTS : {}'.format(tte-tts))\n",
    "        ################## TRAINING INIT ##################    \n",
    "\n",
    "        if isinstance(validation,pd.DataFrame):\n",
    "            ################## VALIDATION AND PREDICTION ##################\n",
    "            validate(validation,init_info)\n",
    "            ################## VALIDATION AND PREDICTION ##################\n",
    "            print('\\n\\t #### CODE EXECUTED SUCCESSFULLY ####')\n",
    "            print('\\n\\t #### END ####')\n",
    "        else:\n",
    "            print('\\n\\t #### CODE DID NOT RUN COMPLETELY ####')\n",
    "except KeyboardInterrupt:\n",
    "    print('QUITTING!')\n",
    "ee = time.time()\n",
    "print('\\n#### TOTAL TIME TAKEN : {} ####'.format(ee-te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nc8N2zjbnp2I"
   },
   "source": [
    "**Preview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "OBzlekYZzs6f",
    "outputId": "0b39636c-53d8-4576-80ac-3f4cda95f01b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>Actual Values</th>\n",
       "      <th>Predicted Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6181-axxyf</td>\n",
       "      <td>1859.10</td>\n",
       "      <td>1784.182490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1268-asbga</td>\n",
       "      <td>1375.15</td>\n",
       "      <td>1368.936724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4159-naaix</td>\n",
       "      <td>5976.64</td>\n",
       "      <td>5921.268021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1219-nnddo</td>\n",
       "      <td>663.55</td>\n",
       "      <td>695.593345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9625-qstye</td>\n",
       "      <td>952.30</td>\n",
       "      <td>1040.160835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>9541-pwtwo</td>\n",
       "      <td>4233.95</td>\n",
       "      <td>4232.534491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>7663-yjhsn</td>\n",
       "      <td>5976.64</td>\n",
       "      <td>5976.746524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>9445-zueqe</td>\n",
       "      <td>2151.60</td>\n",
       "      <td>2290.599542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>8515-octjs</td>\n",
       "      <td>692.10</td>\n",
       "      <td>613.531973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>6839-itvzj</td>\n",
       "      <td>1616.15</td>\n",
       "      <td>1569.933384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    customerID  Actual Values  Predicted Values\n",
       "0   6181-axxyf        1859.10       1784.182490\n",
       "1   1268-asbga        1375.15       1368.936724\n",
       "2   4159-naaix        5976.64       5921.268021\n",
       "3   1219-nnddo         663.55        695.593345\n",
       "4   9625-qstye         952.30       1040.160835\n",
       "..         ...            ...               ...\n",
       "95  9541-pwtwo        4233.95       4232.534491\n",
       "96  7663-yjhsn        5976.64       5976.746524\n",
       "97  9445-zueqe        2151.60       2290.599542\n",
       "98  8515-octjs         692.10        613.531973\n",
       "99  6839-itvzj        1616.15       1569.933384\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View Preview Here\n",
    "pd.read_csv('preview.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_3P-mDe0W-qy"
   },
   "source": [
    "# Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "8Za8q7iXW-qy",
    "outputId": "f003cc95-0ecc-424a-c216-ec2529194cc8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Accuracy%</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>BIC</th>\n",
       "      <th>Total time(mins)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ensemble CatBoost+Light GBM+Random Forest+Extr...</td>\n",
       "      <td>99.89%</td>\n",
       "      <td>66.651371</td>\n",
       "      <td>4.442405e+03</td>\n",
       "      <td>44.204292</td>\n",
       "      <td>11868.068888</td>\n",
       "      <td>0.123249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraTrees Regressor</td>\n",
       "      <td>99.88%</td>\n",
       "      <td>70.567262</td>\n",
       "      <td>4.979738e+03</td>\n",
       "      <td>47.272046</td>\n",
       "      <td>12028.722129</td>\n",
       "      <td>0.006087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>99.87%</td>\n",
       "      <td>73.160200</td>\n",
       "      <td>5.352415e+03</td>\n",
       "      <td>47.527618</td>\n",
       "      <td>12130.265982</td>\n",
       "      <td>0.102405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Light GBM</td>\n",
       "      <td>99.87%</td>\n",
       "      <td>73.160200</td>\n",
       "      <td>5.352415e+03</td>\n",
       "      <td>47.527618</td>\n",
       "      <td>12130.265982</td>\n",
       "      <td>0.001877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>99.87%</td>\n",
       "      <td>71.267552</td>\n",
       "      <td>5.079064e+03</td>\n",
       "      <td>46.725249</td>\n",
       "      <td>12056.509868</td>\n",
       "      <td>0.011212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>99.84%</td>\n",
       "      <td>79.844724</td>\n",
       "      <td>6.375180e+03</td>\n",
       "      <td>55.252573</td>\n",
       "      <td>12376.300315</td>\n",
       "      <td>0.010407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>9.29%</td>\n",
       "      <td>1916.584966</td>\n",
       "      <td>3.673298e+06</td>\n",
       "      <td>1733.518491</td>\n",
       "      <td>21319.801318</td>\n",
       "      <td>0.003570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>89.98%</td>\n",
       "      <td>636.971291</td>\n",
       "      <td>4.057324e+05</td>\n",
       "      <td>531.011000</td>\n",
       "      <td>18219.967489</td>\n",
       "      <td>0.000064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>89.98%</td>\n",
       "      <td>636.950272</td>\n",
       "      <td>4.057056e+05</td>\n",
       "      <td>530.793770</td>\n",
       "      <td>18219.874629</td>\n",
       "      <td>0.000060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>-0.00%</td>\n",
       "      <td>2012.299318</td>\n",
       "      <td>4.049349e+06</td>\n",
       "      <td>1728.911211</td>\n",
       "      <td>21456.936174</td>\n",
       "      <td>0.038652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name Accuracy%         RMSE  \\\n",
       "9  Ensemble CatBoost+Light GBM+Random Forest+Extr...    99.89%    66.651371   \n",
       "4                               ExtraTrees Regressor    99.88%    70.567262   \n",
       "1                                           CatBoost    99.87%    73.160200   \n",
       "2                                          Light GBM    99.87%    73.160200   \n",
       "3                                      Random Forest    99.87%    71.267552   \n",
       "0                                            XGBoost    99.84%    79.844724   \n",
       "8                             Support Vector Machine     9.29%  1916.584966   \n",
       "5                                   Ridge Regression    89.98%   636.971291   \n",
       "6                                  Linear Regression    89.98%   636.950272   \n",
       "7                                         Neural Net    -0.00%  2012.299318   \n",
       "\n",
       "            MSE          MAE           BIC  Total time(mins)  \n",
       "9  4.442405e+03    44.204292  11868.068888          0.123249  \n",
       "4  4.979738e+03    47.272046  12028.722129          0.006087  \n",
       "1  5.352415e+03    47.527618  12130.265982          0.102405  \n",
       "2  5.352415e+03    47.527618  12130.265982          0.001877  \n",
       "3  5.079064e+03    46.725249  12056.509868          0.011212  \n",
       "0  6.375180e+03    55.252573  12376.300315          0.010407  \n",
       "8  3.673298e+06  1733.518491  21319.801318          0.003570  \n",
       "5  4.057324e+05   531.011000  18219.967489          0.000064  \n",
       "6  4.057056e+05   530.793770  18219.874629          0.000060  \n",
       "7  4.049349e+06  1728.911211  21456.936174          0.038652  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_info=pd.DataFrame()\n",
    "model_info=joblib.load('ALL INFORMATION')['model_info'].drop(['model','param','accuracy'],axis=1)\n",
    "model_info.sort_values('Accuracy%',ascending=False,inplace=True)\n",
    "model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# validate(validation,init_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = joblib.load('X')\n",
    "# y = joblib.load('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_cols = getDateColumns(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_engineering(X[date_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init_info,validation = INIT(df,info)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SAWADEEKA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1b9379302ba643c292e33a1d16a2e872": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24fc9010901740679c49571afdb6af08": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2d7d099028864b66bf6457676d0cfba4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Pandas Apply: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fad02bdb1e748a69bd71faf4e417d7d",
      "max": 23,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a313c13925be48949198b0e59006e842",
      "value": 23
     }
    },
    "364c3c26e6b449dd937188e102d8187a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d389453f1854c9ca588f508045fea82": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2d7d099028864b66bf6457676d0cfba4",
       "IPY_MODEL_6df49d042cb845988a38c369725ccb4d"
      ],
      "layout": "IPY_MODEL_f74f0b3c5896413cbd6e50828658cba3"
     }
    },
    "3f12adb7bd824cbaa58acb0ab50a44b1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c9b0446b2c3406690e048208bc68848": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Pandas Apply: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72ffbe6cb217412e9b3e4fcba38c771b",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aeaad849062f40e1934c6314a24308c3",
      "value": 6
     }
    },
    "4d23402341ba43b4bb67151aeb0bf74c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3c4fc04b06d47b2b699b3f6e31aa8fb",
      "placeholder": "​",
      "style": "IPY_MODEL_6cdd8a146e824ad2873f30a3ee0186f7",
      "value": " 6/6 [00:00&lt;00:00, 31.43it/s]"
     }
    },
    "571bbfcf6c434c018a0df5e288116fc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5d01338bb9564ca3ab13cf8bab018480": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f12adb7bd824cbaa58acb0ab50a44b1",
      "placeholder": "​",
      "style": "IPY_MODEL_364c3c26e6b449dd937188e102d8187a",
      "value": " 6/6 [00:00&lt;00:00, 14.74it/s]"
     }
    },
    "61f3492c000447c59bfcd2c4cd7a892e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6cdd8a146e824ad2873f30a3ee0186f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6df49d042cb845988a38c369725ccb4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab7b1ac3f5d249b1a925768b117b1843",
      "placeholder": "​",
      "style": "IPY_MODEL_a0c454b134d9457baf8573dfdef35720",
      "value": " 23/23 [00:00&lt;00:00, 350.68it/s]"
     }
    },
    "72ffbe6cb217412e9b3e4fcba38c771b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79c3dbeda6844b80850c3c0ccee95347": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a369587e849478d98a9e9d65d25df9e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Pandas Apply: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b9379302ba643c292e33a1d16a2e872",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_24fc9010901740679c49571afdb6af08",
      "value": 6
     }
    },
    "7c37357adf69400da78a0a350d754e44": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7a369587e849478d98a9e9d65d25df9e",
       "IPY_MODEL_5d01338bb9564ca3ab13cf8bab018480"
      ],
      "layout": "IPY_MODEL_79c3dbeda6844b80850c3c0ccee95347"
     }
    },
    "80bd764f22064ae4aced600f5e229e57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8586b34d1b4c4cb984a0204b1d9bf300": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d412dd173e9e4818a13bee6e87f6fe31",
       "IPY_MODEL_dd7591443b2544fc942afc5501fbd756"
      ],
      "layout": "IPY_MODEL_f7f7e85b58054caea83f86297c6e24a4"
     }
    },
    "9fad02bdb1e748a69bd71faf4e417d7d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0c454b134d9457baf8573dfdef35720": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a313c13925be48949198b0e59006e842": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ab7b1ac3f5d249b1a925768b117b1843": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aeaad849062f40e1934c6314a24308c3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c039df7ed11040129e03a83dbe1e138d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4c9b0446b2c3406690e048208bc68848",
       "IPY_MODEL_4d23402341ba43b4bb67151aeb0bf74c"
      ],
      "layout": "IPY_MODEL_c48d6b48a10e44ecb77d4bc524f8f9d5"
     }
    },
    "c48d6b48a10e44ecb77d4bc524f8f9d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d412dd173e9e4818a13bee6e87f6fe31": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Pandas Apply: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80bd764f22064ae4aced600f5e229e57",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_571bbfcf6c434c018a0df5e288116fc1",
      "value": 1
     }
    },
    "d52d175248b94390a28f2f443f34e77c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd7591443b2544fc942afc5501fbd756": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_61f3492c000447c59bfcd2c4cd7a892e",
      "placeholder": "​",
      "style": "IPY_MODEL_d52d175248b94390a28f2f443f34e77c",
      "value": " 1/0 [00:00&lt;00:00,  4.00it/s]"
     }
    },
    "f3c4fc04b06d47b2b699b3f6e31aa8fb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f74f0b3c5896413cbd6e50828658cba3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f7f7e85b58054caea83f86297c6e24a4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
