{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proton Training and Validation Modularized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install swifter\n",
    "# !pip3 install xgboost\n",
    "# !pip3 install tqdm\n",
    "# !pip3 install category_encoders\n",
    "# !pip3 install joblib\n",
    "# !pip3 install scikit-plot\n",
    "# !pip3 install catboost\n",
    "# !pip3 install RegscorePy\n",
    "# !pip3 install -U spacy\n",
    "# !pip3 install gensim\n",
    "# !pip3 install xlrd\n",
    "# !pip3 install lightgbm\n",
    "# !pip3 install hyperopt\n",
    "# !pip3 install holidays\n",
    "# !pip3 install textblob\n",
    "# !pip3 install pydotplus\n",
    "# !pip3 install graphviz\n",
    "\n",
    "# Download en_core_web_sm for text analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from userInputs import *\n",
    "from INIT import *\n",
    "from score import *\n",
    "from all_other_functions import targetAnalysis\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from engineerings import numeric_engineering\n",
    "def main():\n",
    "    '''\n",
    "    PROTON MAIN FUNCTION\n",
    "    '''\n",
    "    spinnerBool = False\n",
    "    path = input('Enter the path here : ')\n",
    "    error = False\n",
    "    if path:\n",
    "        df,csvPath = importFile(path,nrows=30)\n",
    "        df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "        df = dataHandler(df) # If first few rows contains unnecessary info\n",
    "        info = getUserInput(df)\n",
    "        if not info:\n",
    "            error = True\n",
    "    else:\n",
    "        df = None\n",
    "        print('\\nQuitting Process\\n')\n",
    "        info = None\n",
    "        error = True\n",
    "\n",
    "    te = time.time()\n",
    "    try:\n",
    "        if info:\n",
    "            spinnerBool = True\n",
    "            ################## TRAINING INIT ##################\n",
    "            if csvPath:\n",
    "                path = 'SheetSheetSheet.csv'\n",
    "            df,_ = importFile(path,nrows=None)\n",
    "            df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "            df = dataHandler(df) # If first few rows contains unnecessary info\n",
    "            tts = time.time()\n",
    "            if isinstance(df,pd.DataFrame):\n",
    "                target = info['target']\n",
    "                print(\"###Performing Initial Numeric Engineering for Capping Purposes###\")\n",
    "                dfsamp = df.sample(n=1000,random_state=1) if len(df)>1000 else df.copy()\n",
    "                dfsamp = numeric_engineering(dfsamp)\n",
    "                dfsamp = dfsamp.dropna(axis=0,subset=[target])\n",
    "                class_or_Reg = targetAnalysis(dfsamp[target])                    \n",
    "                if class_or_Reg == 'Classification':\n",
    "                    if len(df) >1000000:\n",
    "                        df_train, _ = train_test_split(df, train_size=1000000,random_state=1, stratify=df[target])\n",
    "                        print(\"Dataset size has been capped to 10 lakh rows for better performance\")\n",
    "                        print(\"Length of the dataset is now\",len(df_train))\n",
    "                        init_info,validation = INIT(df_train,info)\n",
    "                    else:\n",
    "                        print(\"Dataset has not been capped\")\n",
    "                        print(\"Length of the dataset is same as original\",len(df))\n",
    "                        init_info,validation = INIT(df,info)\n",
    "                elif class_or_Reg == 'Regression':\n",
    "                    dfr = df.sample(n=1000000, random_state=1) if len(df)>1000000 else df.copy()\n",
    "                    print(\"Dataset size has been capped to 10 lakh rows for better performance\")\n",
    "                    print(\"Length of the dataset is now\",len(dfr))\n",
    "                    init_info,validation = INIT(dfr,info)\n",
    "                elif class_or_Reg is None:\n",
    "                    init_info,validation = None,None\n",
    "            else:\n",
    "                init_info,validation = None,None\n",
    "            tte = time.time()\n",
    "            print('\\n TOTAL TRAINING DATA CLEANING AND PLOTS : {}'.format(tte-tts))\n",
    "            ################## TRAINING INIT ##################\n",
    "\n",
    "            if isinstance(validation,pd.DataFrame):\n",
    "                ################## VALIDATION AND PREDICTION ##################\n",
    "                score(validation,init_info,validation=True)\n",
    "                ################## VALIDATION AND PREDICTION ##################\n",
    "                print('\\n\\t #### CODE EXECUTED SUCCESSFULLY ####')\n",
    "                print('\\n\\t #### END ####')\n",
    "            else:\n",
    "                print('\\n\\t #### CODE DID NOT RUN COMPLETELY ####')\n",
    "            spinnerBool = False\n",
    "    except KeyboardInterrupt:\n",
    "        print('QUITTING!')   \n",
    "        return None\n",
    "#     except Exception as e:\n",
    "#         print('Code did not run completely')\n",
    "#         print('Code ran into an error')\n",
    "#         print('The error message received is')\n",
    "#         print(e)\n",
    "#         return None\n",
    "    ee = time.time()\n",
    "    print('\\n#### TOTAL TIME TAKEN : {} ####'.format(ee-te))\n",
    "    return 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Main Function call\n",
    "    ret = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = pd.read_csv('preview.csv')\n",
    "pre.index = np.arange(1,len(pre)+1)\n",
    "\n",
    "# Set CSS properties for th elements in dataframe\n",
    "th_prop = [\n",
    "    ('padding', '5px'),\n",
    "    ('font-family', 'arial'),\n",
    "    ('font-size', '100%'),\n",
    "    ('color', 'Black'),\n",
    "    ('border', '1px') ,\n",
    "    ('border', 'solid black'),\n",
    "    ('text-align', 'center')\n",
    "  ]\n",
    "\n",
    "# Set CSS properties for td elements in dataframe\n",
    "td_prop = [\n",
    "#     ('background', 'rgb(232, 247, 252)'),\n",
    "    ('border', '1px'),\n",
    "    ('border','solid black'),\n",
    "    ('color', 'black'),\n",
    "    ('font-family', 'arial')\n",
    "  ]\n",
    "\n",
    "# Set table styles\n",
    "styls = [\n",
    "  dict(selector=\"th\", props=th_prop),\n",
    "  dict(selector=\"td\", props=td_prop),\n",
    "  dict(selector=\"caption\", props=[(\"text-align\", \"left\"),(\"font-size\", \"120%\"),(\"color\", 'black')])\n",
    "  ]\n",
    "\n",
    "pre.style.set_table_styles(styls).set_caption(\"Preview of Test Dataset(100 rows) with Predictions and Actual Values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set CSS properties for th elements in dataframe\n",
    "th_props = [\n",
    "    ('background', 'rgb(12, 64, 90)'),\n",
    "    ('background', 'linear-gradient(0deg, rgba(21, 112, 157) 0%, rgba(12, 64, 90) 120%)'),\n",
    "    ('padding', '5px'),\n",
    "    ('font-family', 'arial'),\n",
    "    ('font-size', '100%'),\n",
    "    ('color', 'white'),\n",
    "    ('border', '2px') ,\n",
    "    ('border', 'solid white'),\n",
    "    ('text-align', 'center')\n",
    "  ]\n",
    "\n",
    "# Set CSS properties for td elements in dataframe\n",
    "td_props = [\n",
    "#     ('background', 'rgb(232, 247, 252)'),\n",
    "    ('border', '2px'),\n",
    "    ('border','solid white')    \n",
    "  ]\n",
    "\n",
    "# Set table styles\n",
    "styles = [\n",
    "  dict(selector=\"th\", props=th_props),\n",
    "  dict(selector=\"td\", props=td_props),\n",
    "  dict(selector=\"caption\", props=[(\"text-align\", \"left\"),(\"font-size\", \"120%\"),(\"color\", 'black')])\n",
    "  ]\n",
    "\n",
    "def color_func(value):           # setting different color for F1 or RMSE column\n",
    "    if value.name in ['Weighted F1','RMSE']:\n",
    "        color= '#f7f7ba'\n",
    "    else:\n",
    "#         print(value)\n",
    "        color= '#e8f7fc'\n",
    "    return ['background-color: %s' %color]*len(value)\n",
    "\n",
    "\n",
    "MC = pd.read_csv('MC.csv')\n",
    "if 'Weighted F1' in MC.columns:          # for setting caption\n",
    "    cap='This table is sorted by F1 Score(Weighted F1), higher the better'\n",
    "else:\n",
    "    cap ='This table is sorted by Root Mean Squared Error(RMSE), lower the better'\n",
    "MC.index = np.arange(1,len(MC)+1)       # adjusting index\n",
    "if 'Weighted F1' in MC.columns:        #for setting decimal places\n",
    "    mc= MC.style.set_table_styles(styles).set_caption(cap).apply(color_func, axis=0).set_precision(3)\n",
    "else:\n",
    "    mc= MC.style.set_table_styles(styles).set_caption(cap).apply(color_func, axis=0).set_precision(2)\n",
    "    \n",
    "mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('XT').min().min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('Xt').min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('XT').max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('Xt').max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('YT').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('Yt').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('YT').min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('Yt').min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# # df = pd.read_csv('SheetSheetSheet.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
