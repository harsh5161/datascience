{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proton Training and Validation Modularized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install swifter\n",
    "# !pip3 install xgboost\n",
    "# !pip3 install tqdm\n",
    "# !pip3 install category_encoders\n",
    "# !pip3 install joblib\n",
    "# !pip3 install scikit-plot\n",
    "# !pip3 install catboost\n",
    "# !pip3 install RegscorePy\n",
    "# !pip3 install -U spacy\n",
    "# !pip3 install gensim\n",
    "# !pip3 install xlrd\n",
    "# !pip3 install lightgbm\n",
    "# !pip3 install hyperopt\n",
    "# !pip3 install holidays\n",
    "# !pip3 install textblob\n",
    "# !pip3 install pydotplus\n",
    "# !pip3 install graphviz\n",
    "\n",
    "# Download en_core_web_sm for text analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from userInputs import *\n",
    "from INIT import *\n",
    "from score import *\n",
    "from all_other_functions import targetAnalysis\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def main():\n",
    "    '''\n",
    "    PROTON MAIN FUNCTION\n",
    "    '''\n",
    "    spinnerBool = False\n",
    "    path = input('Enter the path here : ')\n",
    "    error = False\n",
    "    if path:\n",
    "        df,csvPath = importFile(path,nrows=30)\n",
    "        df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "        df = dataHandler(df) # If first few rows contains unnecessary info\n",
    "        info = getUserInput(df)\n",
    "        if not info:\n",
    "            error = True\n",
    "    else:\n",
    "        df = None\n",
    "        print('\\nQuitting Process\\n')\n",
    "        info = None\n",
    "        error = True\n",
    "\n",
    "    te = time.time()\n",
    "    try:\n",
    "        if info:\n",
    "            spinnerBool = True\n",
    "            ################## TRAINING INIT ##################\n",
    "            if csvPath:\n",
    "                path = 'SheetSheetSheet.csv'\n",
    "            df,_ = importFile(path,nrows=None)\n",
    "            df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "            df = dataHandler(df) # If first few rows contains unnecessary info\n",
    "            tts = time.time()\n",
    "            if isinstance(df,pd.DataFrame):\n",
    "                target = info['target']\n",
    "                df = df.dropna(axis=0,subset=[target])\n",
    "                class_or_Reg = targetAnalysis(df[target])\n",
    "                if class_or_Reg == 'Classification':\n",
    "                    if len(df) >1000000:\n",
    "                        df_train, _ = train_test_split(df, train_size=1000000,random_state=1, stratify=df[target])\n",
    "                        print(\"Dataset size has been capped\")\n",
    "                        init_info,validation = INIT(df_train,info)\n",
    "                    else:\n",
    "                        init_info,validation = INIT(df,info)\n",
    "                elif class_or_Reg == 'Regression':\n",
    "                    dfr = df.sample(n=1000000, random_state=1) if len(df)>1000000 else df.copy()\n",
    "                    init_info,validation = INIT(dfr,info)\n",
    "                elif class_or_Reg is None:\n",
    "                    init_info,validation = None,None\n",
    "            else:\n",
    "                init_info,validation = None,None\n",
    "            tte = time.time()\n",
    "            print('\\n TOTAL TRAINING DATA CLEANING AND PLOTS : {}'.format(tte-tts))\n",
    "            ################## TRAINING INIT ##################\n",
    "\n",
    "            if isinstance(validation,pd.DataFrame):\n",
    "                ################## VALIDATION AND PREDICTION ##################\n",
    "                score(validation,init_info,validation=True)\n",
    "                ################## VALIDATION AND PREDICTION ##################\n",
    "                print('\\n\\t #### CODE EXECUTED SUCCESSFULLY ####')\n",
    "                print('\\n\\t #### END ####')\n",
    "            else:\n",
    "                print('\\n\\t #### CODE DID NOT RUN COMPLETELY ####')\n",
    "            spinnerBool = False\n",
    "    except KeyboardInterrupt:\n",
    "        print('QUITTING!')   \n",
    "        return None\n",
    "#     except Exception as e:\n",
    "#         print('Code did not run completely')\n",
    "#         print('Code ran into an error')\n",
    "#         print('The error message received is')\n",
    "#         print(e)\n",
    "#         return None\n",
    "    ee = time.time()\n",
    "    print('\\n#### TOTAL TIME TAKEN : {} ####'.format(ee-te))\n",
    "    return 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Main Function call\n",
    "    ret = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = pd.read_csv('preview.csv')\n",
    "pre.index = np.arange(1,len(pre)+1)\n",
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "MC = pd.read_csv('MC.csv')\n",
    "if 'F1' in MC.columns:print('Sorted by F1 Score(F1),higher the better')\n",
    "else:print('Sorted by Root Mean Squared Error(RMSE),lower the better')\n",
    "MC.index = np.arange(1,len(MC)+1)\n",
    "MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('XT').min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('Xt').min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('XT').max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('Xt').max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('YT').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('Yt').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('YT').min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.load('Yt').min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# # df = pd.read_csv('SheetSheetSheet.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}